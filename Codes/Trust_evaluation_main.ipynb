{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "173cc7e6-0bdc-4275-9192-12cd79f0770a",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7be600-e4c5-4a4c-8fa0-9f07306d57a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column1     0\n",
      "Column2     0\n",
      "Column3     0\n",
      "Column4     0\n",
      "Column5     0\n",
      "Column6     0\n",
      "Column7     0\n",
      "Column8     0\n",
      "Column9     0\n",
      "Column10    0\n",
      "Column11    0\n",
      "Column12    0\n",
      "Column13    0\n",
      "Column14    0\n",
      "Column15    0\n",
      "Column16    0\n",
      "Column17    0\n",
      "Column18    0\n",
      "Column19    0\n",
      "Column20    0\n",
      "Column21    0\n",
      "Column22    0\n",
      "Column23    0\n",
      "Column24    0\n",
      "Column25    0\n",
      "dtype: int64\n",
      "Column1     0\n",
      "Column2     0\n",
      "Column3     0\n",
      "Column4     0\n",
      "Column5     0\n",
      "Column6     0\n",
      "Column7     0\n",
      "Column8     0\n",
      "Column9     0\n",
      "Column10    0\n",
      "Column11    0\n",
      "Column12    0\n",
      "Column13    0\n",
      "Column14    0\n",
      "Column15    0\n",
      "Column16    0\n",
      "Column17    0\n",
      "Column18    0\n",
      "Column19    0\n",
      "Column20    0\n",
      "Column21    0\n",
      "Column22    0\n",
      "Column23    0\n",
      "Column24    0\n",
      "Column25    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(\"C:/Users/Psps0/Trust Evaluation/german-data-numeric.xlsx\")\n",
    "\n",
    "# Handle missing values\n",
    "# For simplicity, we will use median for numerical columns\n",
    "for column in df.columns:\n",
    "    df[column].fillna(df[column].median(), inplace=True)\n",
    "\n",
    "# Check for any remaining anomalies\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Impute remaining numerical columns with mean\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "\n",
    "# Final check\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85245d-a720-445f-8aed-904b70b0293f",
   "metadata": {},
   "source": [
    "# ANN-LSTM Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fdd771f9-81ca-426a-aa3e-65071b1d09e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Psps0\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 247ms/step - binary_accuracy: 0.5081 - loss: 0.6919 - val_binary_accuracy: 0.5500 - val_loss: 0.6877 - learning_rate: 0.0010\n",
      "Epoch 2/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - binary_accuracy: 0.5104 - loss: 0.6892 - val_binary_accuracy: 0.5500 - val_loss: 0.6876 - learning_rate: 0.0010\n",
      "Epoch 3/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - binary_accuracy: 0.6321 - loss: 0.6657 - val_binary_accuracy: 0.5000 - val_loss: 0.6873 - learning_rate: 0.0010\n",
      "Epoch 4/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - binary_accuracy: 0.5628 - loss: 0.6647 - val_binary_accuracy: 0.6000 - val_loss: 0.6858 - learning_rate: 0.0010\n",
      "Epoch 5/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.5504 - loss: 0.6620 - val_binary_accuracy: 0.6000 - val_loss: 0.6819 - learning_rate: 0.0010\n",
      "Epoch 6/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.6984 - loss: 0.6365 - val_binary_accuracy: 0.6000 - val_loss: 0.6753 - learning_rate: 0.0010\n",
      "Epoch 7/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - binary_accuracy: 0.6474 - loss: 0.6315 - val_binary_accuracy: 0.6000 - val_loss: 0.6672 - learning_rate: 0.0010\n",
      "Epoch 8/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.6350 - loss: 0.6169 - val_binary_accuracy: 0.6000 - val_loss: 0.6567 - learning_rate: 0.0010\n",
      "Epoch 9/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - binary_accuracy: 0.6335 - loss: 0.6108 - val_binary_accuracy: 0.6000 - val_loss: 0.6435 - learning_rate: 0.0010\n",
      "Epoch 10/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.7222 - loss: 0.5925 - val_binary_accuracy: 0.6500 - val_loss: 0.6281 - learning_rate: 0.0010\n",
      "Epoch 11/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.7725 - loss: 0.5636 - val_binary_accuracy: 0.6500 - val_loss: 0.6124 - learning_rate: 0.0010\n",
      "Epoch 12/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - binary_accuracy: 0.7627 - loss: 0.5258 - val_binary_accuracy: 0.6500 - val_loss: 0.5994 - learning_rate: 0.0010\n",
      "Epoch 13/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - binary_accuracy: 0.7314 - loss: 0.5337 - val_binary_accuracy: 0.6500 - val_loss: 0.5881 - learning_rate: 0.0010\n",
      "Epoch 14/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.7580 - loss: 0.5322 - val_binary_accuracy: 0.7000 - val_loss: 0.5776 - learning_rate: 0.0010\n",
      "Epoch 15/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - binary_accuracy: 0.7396 - loss: 0.5210 - val_binary_accuracy: 0.7500 - val_loss: 0.5631 - learning_rate: 0.0010\n",
      "Epoch 16/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.7964 - loss: 0.4751 - val_binary_accuracy: 0.7500 - val_loss: 0.5348 - learning_rate: 0.0010\n",
      "Epoch 17/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - binary_accuracy: 0.7826 - loss: 0.5123 - val_binary_accuracy: 0.8000 - val_loss: 0.5074 - learning_rate: 0.0010\n",
      "Epoch 18/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.8295 - loss: 0.4452 - val_binary_accuracy: 0.8000 - val_loss: 0.4843 - learning_rate: 0.0010\n",
      "Epoch 19/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.8486 - loss: 0.4295 - val_binary_accuracy: 0.8500 - val_loss: 0.4713 - learning_rate: 0.0010\n",
      "Epoch 20/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.8736 - loss: 0.3708 - val_binary_accuracy: 0.8000 - val_loss: 0.4698 - learning_rate: 0.0010\n",
      "Epoch 21/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - binary_accuracy: 0.8808 - loss: 0.4089 - val_binary_accuracy: 0.8000 - val_loss: 0.4731 - learning_rate: 0.0010\n",
      "Epoch 22/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.8631 - loss: 0.4068 - val_binary_accuracy: 0.8000 - val_loss: 0.4726 - learning_rate: 0.0010\n",
      "Epoch 23/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - binary_accuracy: 0.8709 - loss: 0.3307 - val_binary_accuracy: 0.7500 - val_loss: 0.4722 - learning_rate: 0.0010\n",
      "Epoch 24/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.8703 - loss: 0.3696 - val_binary_accuracy: 0.8000 - val_loss: 0.4467 - learning_rate: 0.0010\n",
      "Epoch 25/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - binary_accuracy: 0.9217 - loss: 0.3005 - val_binary_accuracy: 0.8000 - val_loss: 0.4417 - learning_rate: 0.0010\n",
      "Epoch 26/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9332 - loss: 0.2525 - val_binary_accuracy: 0.8000 - val_loss: 0.4448 - learning_rate: 0.0010\n",
      "Epoch 27/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9248 - loss: 0.3007 - val_binary_accuracy: 0.8000 - val_loss: 0.4502 - learning_rate: 0.0010\n",
      "Epoch 28/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9409 - loss: 0.2879 - val_binary_accuracy: 0.8000 - val_loss: 0.4493 - learning_rate: 0.0010\n",
      "Epoch 29/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - binary_accuracy: 0.9498 - loss: 0.2075 - val_binary_accuracy: 0.8000 - val_loss: 0.4377 - learning_rate: 0.0010\n",
      "Epoch 30/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - binary_accuracy: 0.9461 - loss: 0.2334 - val_binary_accuracy: 0.8500 - val_loss: 0.4293 - learning_rate: 0.0010\n",
      "Epoch 31/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9492 - loss: 0.2214 - val_binary_accuracy: 0.8500 - val_loss: 0.4245 - learning_rate: 0.0010\n",
      "Epoch 32/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9761 - loss: 0.1883 - val_binary_accuracy: 0.8500 - val_loss: 0.4339 - learning_rate: 0.0010\n",
      "Epoch 33/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.9912 - loss: 0.1486 - val_binary_accuracy: 0.8500 - val_loss: 0.4403 - learning_rate: 0.0010\n",
      "Epoch 34/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.9907 - loss: 0.1929 - val_binary_accuracy: 0.8500 - val_loss: 0.4505 - learning_rate: 0.0010\n",
      "Epoch 35/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.9761 - loss: 0.1713 - val_binary_accuracy: 0.8500 - val_loss: 0.4513 - learning_rate: 0.0010\n",
      "Epoch 36/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.9912 - loss: 0.1487 - val_binary_accuracy: 0.8500 - val_loss: 0.4461 - learning_rate: 0.0010\n",
      "Epoch 37/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9849 - loss: 0.1591 - val_binary_accuracy: 0.8500 - val_loss: 0.4450 - learning_rate: 2.0000e-04\n",
      "Epoch 38/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - binary_accuracy: 0.9761 - loss: 0.1647 - val_binary_accuracy: 0.8500 - val_loss: 0.4452 - learning_rate: 2.0000e-04\n",
      "Epoch 39/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - binary_accuracy: 0.9793 - loss: 0.1398 - val_binary_accuracy: 0.8500 - val_loss: 0.4451 - learning_rate: 2.0000e-04\n",
      "Epoch 40/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9912 - loss: 0.1367 - val_binary_accuracy: 0.8500 - val_loss: 0.4471 - learning_rate: 2.0000e-04\n",
      "Epoch 41/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - binary_accuracy: 0.9849 - loss: 0.1548 - val_binary_accuracy: 0.8500 - val_loss: 0.4424 - learning_rate: 2.0000e-04\n",
      "Epoch 42/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9548 - loss: 0.1873 - val_binary_accuracy: 0.8500 - val_loss: 0.4421 - learning_rate: 4.0000e-05\n",
      "Epoch 43/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9912 - loss: 0.1644 - val_binary_accuracy: 0.8500 - val_loss: 0.4422 - learning_rate: 4.0000e-05\n",
      "Epoch 44/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - binary_accuracy: 0.9943 - loss: 0.1902 - val_binary_accuracy: 0.8500 - val_loss: 0.4425 - learning_rate: 4.0000e-05\n",
      "Epoch 45/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.9943 - loss: 0.1158 - val_binary_accuracy: 0.8500 - val_loss: 0.4431 - learning_rate: 4.0000e-05\n",
      "Epoch 46/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9912 - loss: 0.1497 - val_binary_accuracy: 0.8500 - val_loss: 0.4438 - learning_rate: 4.0000e-05\n",
      "Epoch 47/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.9849 - loss: 0.1942 - val_binary_accuracy: 0.8500 - val_loss: 0.4440 - learning_rate: 8.0000e-06\n",
      "Epoch 48/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - binary_accuracy: 0.9964 - loss: 0.1070 - val_binary_accuracy: 0.8500 - val_loss: 0.4441 - learning_rate: 8.0000e-06\n",
      "Epoch 49/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9943 - loss: 0.1612 - val_binary_accuracy: 0.8500 - val_loss: 0.4442 - learning_rate: 8.0000e-06\n",
      "Epoch 50/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - binary_accuracy: 0.9943 - loss: 0.1147 - val_binary_accuracy: 0.8500 - val_loss: 0.4444 - learning_rate: 8.0000e-06\n",
      "Epoch 51/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - binary_accuracy: 0.9964 - loss: 0.1467 - val_binary_accuracy: 0.8500 - val_loss: 0.4445 - learning_rate: 8.0000e-06\n",
      "Epoch 52/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9912 - loss: 0.1438 - val_binary_accuracy: 0.8500 - val_loss: 0.4445 - learning_rate: 1.6000e-06\n",
      "Epoch 53/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - binary_accuracy: 0.9964 - loss: 0.0850 - val_binary_accuracy: 0.8500 - val_loss: 0.4445 - learning_rate: 1.6000e-06\n",
      "Epoch 54/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - binary_accuracy: 0.9943 - loss: 0.0998 - val_binary_accuracy: 0.8500 - val_loss: 0.4446 - learning_rate: 1.6000e-06\n",
      "Epoch 55/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - binary_accuracy: 0.9824 - loss: 0.1421 - val_binary_accuracy: 0.8500 - val_loss: 0.4446 - learning_rate: 1.6000e-06\n",
      "Epoch 56/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - binary_accuracy: 0.9886 - loss: 0.1909 - val_binary_accuracy: 0.8500 - val_loss: 0.4446 - learning_rate: 1.6000e-06\n",
      "Epoch 57/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - binary_accuracy: 0.9964 - loss: 0.1199 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 58/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9761 - loss: 0.1411 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 59/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9793 - loss: 0.1792 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 60/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - binary_accuracy: 0.9849 - loss: 0.1742 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 61/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - binary_accuracy: 0.9943 - loss: 0.1713 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 62/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9824 - loss: 0.1409 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 63/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - binary_accuracy: 0.9912 - loss: 0.1288 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 64/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - binary_accuracy: 0.9912 - loss: 0.1342 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 65/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9912 - loss: 0.2076 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 66/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - binary_accuracy: 0.9964 - loss: 0.1306 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 67/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9793 - loss: 0.1258 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 68/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - binary_accuracy: 0.9943 - loss: 0.0981 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 69/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9849 - loss: 0.1360 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 70/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - binary_accuracy: 0.9699 - loss: 0.1996 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 71/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - binary_accuracy: 0.9964 - loss: 0.1123 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 72/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9849 - loss: 0.1374 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 73/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - binary_accuracy: 0.9943 - loss: 0.1816 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 74/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - binary_accuracy: 0.9964 - loss: 0.1387 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 75/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - binary_accuracy: 0.9849 - loss: 0.1456 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 76/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9849 - loss: 0.1533 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 77/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - binary_accuracy: 0.9761 - loss: 0.1175 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 78/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9943 - loss: 0.1243 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 79/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - binary_accuracy: 0.9849 - loss: 0.2297 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 80/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9886 - loss: 0.1326 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 81/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9943 - loss: 0.0962 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 82/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - binary_accuracy: 0.9912 - loss: 0.1395 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 83/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9912 - loss: 0.1763 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 84/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9849 - loss: 0.1513 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 85/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9943 - loss: 0.1845 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 86/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9912 - loss: 0.1555 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 87/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - binary_accuracy: 0.9943 - loss: 0.1160 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 88/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - binary_accuracy: 0.9849 - loss: 0.1256 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 89/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - binary_accuracy: 0.9912 - loss: 0.1452 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 90/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - binary_accuracy: 0.9849 - loss: 0.1833 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 91/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - binary_accuracy: 0.9943 - loss: 0.1616 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 92/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - binary_accuracy: 0.9943 - loss: 0.1550 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 93/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9943 - loss: 0.1099 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 94/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9912 - loss: 0.1492 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 95/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - binary_accuracy: 0.9813 - loss: 0.2130 - val_binary_accuracy: 0.8500 - val_loss: 0.4448 - learning_rate: 1.0000e-06\n",
      "Epoch 96/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9849 - loss: 0.1303 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 97/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.9761 - loss: 0.1087 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 98/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - binary_accuracy: 0.9912 - loss: 0.1482 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 99/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9761 - loss: 0.1481 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 100/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - binary_accuracy: 0.9849 - loss: 0.1926 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 101/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9849 - loss: 0.1720 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 102/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9943 - loss: 0.1308 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 103/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - binary_accuracy: 0.9943 - loss: 0.1003 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 104/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - binary_accuracy: 0.9849 - loss: 0.1582 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 105/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - binary_accuracy: 0.9943 - loss: 0.1674 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 106/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - binary_accuracy: 0.9912 - loss: 0.1785 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 107/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9943 - loss: 0.1260 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 108/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - binary_accuracy: 0.9943 - loss: 0.1403 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 109/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - binary_accuracy: 0.9943 - loss: 0.1146 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "Epoch 110/110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - binary_accuracy: 0.9849 - loss: 0.1801 - val_binary_accuracy: 0.8500 - val_loss: 0.4447 - learning_rate: 1.0000e-06\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - binary_accuracy: 0.8500 - loss: 0.4447\n",
      "Test Accuracy: 85.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the cleaned dataset\n",
    "cleaned_german_data_numeric = pd.read_excel(\"C:/Users/Psps0/Trust Evaluation/german-data-numeric.xlsx\")\n",
    "\n",
    "# Verify that 'Column25' exists in the dataset\n",
    "if 'Column25' not in cleaned_german_data_numeric.columns:\n",
    "    raise ValueError(\"The 'Column25' column is not found in the dataset.\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = cleaned_german_data_numeric.drop(columns=['Column25'])\n",
    "y = cleaned_german_data_numeric['Column25']\n",
    "\n",
    "# Convert target variable to binary (0 and 1)\n",
    "y = y.map({1: 0, 2: 1})\n",
    "\n",
    "# Check if target is binary\n",
    "if not set(y.unique()).issubset({0, 1}):\n",
    "    raise ValueError(\"The target variable 'Column25' must be binary (0 and 1).\")\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20 ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure all numeric columns are indeed numeric\n",
    "numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "X_train[numeric_columns] = X_train[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "X_test[numeric_columns] = X_test[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "if X_train.isnull().values.any() or X_test.isnull().values.any():\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train[numeric_columns] = imputer.fit_transform(X_train[numeric_columns])\n",
    "    X_test[numeric_columns] = imputer.transform(X_test[numeric_columns])\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Handle data imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Assuming each sample has a time series sequence length of 10 (timesteps)\n",
    "timesteps = 10\n",
    "\n",
    "# Reshape the training and testing features for LSTM input\n",
    "num_samples = len(X_train_resampled) // timesteps * timesteps\n",
    "X_train_reshaped = X_train_resampled[:num_samples].reshape(-1, timesteps, X_train_resampled.shape[1])\n",
    "y_train_reshaped = y_train_resampled[:num_samples].values.reshape(-1, timesteps)[:, 0]  # Target should be the same for each sequence\n",
    "\n",
    "num_samples_test = len(X_test_scaled) // timesteps * timesteps\n",
    "X_test_reshaped = X_test_scaled[:num_samples_test].reshape(-1, timesteps, X_test_scaled.shape[1])\n",
    "y_test_reshaped = y_test[:num_samples_test].values.reshape(-1, timesteps)[:, 0]\n",
    "\n",
    "# Define the LSTM model with simpler architecture\n",
    "model = Sequential([\n",
    "    LSTM(32, return_sequences=True, input_shape=(timesteps, X_train_reshaped.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(16),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "\n",
    "history = model.fit(X_train_reshaped, y_train_reshaped, epochs=110, batch_size=32,\n",
    "                    validation_data=(X_test_reshaped, y_test_reshaped),\n",
    "                    callbacks=[reduce_lr])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test_reshaped)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f171c-813f-4fe9-857a-d7cc16004009",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0aa0fe11-9ff9-4600-ae93-fbd4d28b2e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88        14\n",
      "           1       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.83      0.89      0.84        20\n",
      "weighted avg       0.90      0.85      0.86        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test_reshaped, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515cf830-16e6-4ead-bbb3-9b0a3665bb27",
   "metadata": {},
   "source": [
    "# True Positive, True Negative, False Positive, False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7df26f3a-3306-4127-9c52-5ac31f23fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "TP: 30\n",
      "FP: 60\n",
      "TN: 80\n",
      "FN: 30\n",
      "Total instances: 200\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "y_pred_probs = model.predict(X_test_reshaped)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Reshape predictions and true labels to match the original shape\n",
    "y_pred = y_pred.reshape(-1)\n",
    "y_true = y_test.values[:len(y_pred)]  # Using original labels before reshaping\n",
    "\n",
    "# Initialize counters\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "# Calculate TP, FP, TN, FN\n",
    "for pred, true in zip(y_pred, y_true):\n",
    "    if true == 1:\n",
    "        if pred == 1:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "    else:\n",
    "        if pred == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "\n",
    "# Calculate total instances (assuming 200)\n",
    "total_instances = 200\n",
    "\n",
    "# Adjust counts for 200 instances\n",
    "TP *= total_instances / len(y_true)\n",
    "FP *= total_instances / len(y_true)\n",
    "TN *= total_instances / len(y_true)\n",
    "FN *= total_instances / len(y_true)\n",
    "\n",
    "print(\"TP:\", int(TP))\n",
    "print(\"FP:\", int(FP))\n",
    "print(\"TN:\", int(TN))\n",
    "print(\"FN:\", int(FN))\n",
    "\n",
    "# Verify total instances\n",
    "print(\"Total instances:\", int(total_instances))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cf9292-b5b1-4f14-bbfe-f136cded63f3",
   "metadata": {},
   "source": [
    "# Confusion MAtrix of ANN-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "254de6da-9ce7-4cf7-b5ac-2f2a832f58ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAGZCAYAAAAU+E8eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAlklEQVR4nO3deVxU9f4/8NcZhAEVEEQUFFFRUckFxRDN6wIuiH7tuqS5XDDUXHLJXK6aopbrrS5pimKAaOaWS2ZJ7qYFAiKuXG+aC+UCGMomyPL5/eFlfo6AcUZgZo6vp4/zyDnzOee8Bz/Nm89yzkcSQggQEREpkErfARAREVUWJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkySBcuXMCYMWPQuHFjmJubo2bNmmjfvj1WrVqFP//8s1Kvfe7cOXTr1g3W1taQJAnBwcEVfg1JkrBo0aIKP+9f2bRpEyRJgiRJOHHiRIn3hRBo2rQpJElC9+7ddbrGunXrsGnTJlnHnDhxosyYiF5GNX0HQPS8jRs3YtKkSXB1dcWsWbPQqlUr5OfnIz4+HuvXr0d0dDT27t1badd/5513kJ2dje3bt8PGxgaNGjWq8GtER0ejQYMGFX7e8rK0tERYWFiJRHby5Elcv34dlpaWOp973bp1sLOzQ0BAQLmPad++PaKjo9GqVSudr0tUGiY5MijR0dGYOHEievXqhX379kGtVmve69WrFz744ANERUVVagyXLl3CuHHj4OvrW2nX6NSpU6WduzyGDRuGrVu3Yu3atbCystLsDwsLg5eXFzIyMqokjvz8fEiSBCsrK73/TEiZ2F1JBmXZsmWQJAmhoaFaCa6YmZkZ/u///k/zuqioCKtWrUKLFi2gVqthb2+Pf/zjH/j999+1juvevTtee+01xMXFoWvXrqhevTqaNGmCFStWoKioCMD/78orKChASEiIplsPABYtWqT5+7OKj7l586Zm37Fjx9C9e3fUrl0bFhYWaNiwIQYPHoycnBxNmdK6Ky9duoSBAwfCxsYG5ubmaNeuHSIjI7XKFHfrbdu2DfPnz4ejoyOsrKzg4+ODq1evlu+HDODtt98GAGzbtk2z79GjR9i9ezfeeeedUo9ZvHgxPD09YWtrCysrK7Rv3x5hYWF49hnvjRo1wuXLl3Hy5EnNz6+4JVwc+5YtW/DBBx+gfv36UKvVuHbtWonuyrS0NDg5OaFz587Iz8/XnP/KlSuoUaMGRo8eXe7PSq82JjkyGIWFhTh27Bg6dOgAJyench0zceJEzJkzB7169cL+/fvx0UcfISoqCp07d0ZaWppW2Xv37mHkyJEYNWoU9u/fD19fX8ydOxdfffUVAMDPzw/R0dEAgCFDhiA6Olrzurxu3rwJPz8/mJmZITw8HFFRUVixYgVq1KiBJ0+elHnc1atX0blzZ1y+fBmrV6/Gnj170KpVKwQEBGDVqlUlys+bNw+3bt3Cl19+idDQUPz6668YMGAACgsLyxWnlZUVhgwZgvDwcM2+bdu2QaVSYdiwYWV+tnfffRc7d+7Enj17MGjQIEyZMgUfffSRpszevXvRpEkTuLu7a35+z3ctz507F7dv38b69evx3Xffwd7evsS17OzssH37dsTFxWHOnDkAgJycHAwdOhQNGzbE+vXry/U5iSCIDMS9e/cEADF8+PBylU9KShIAxKRJk7T2nzlzRgAQ8+bN0+zr1q2bACDOnDmjVbZVq1aiT58+WvsAiMmTJ2vtCwoKEqX97xIRESEAiBs3bgghhPjmm28EAJGYmPjC2AGIoKAgzevhw4cLtVotbt++rVXO19dXVK9eXTx8+FAIIcTx48cFANGvXz+tcjt37hQARHR09AuvWxxvXFyc5lyXLl0SQgjRsWNHERAQIIQQws3NTXTr1q3M8xQWFor8/HyxZMkSUbt2bVFUVKR5r6xji6/3t7/9rcz3jh8/rrV/5cqVAoDYu3ev8Pf3FxYWFuLChQsv/IxEz2JLjozW8ePHAaDEBIfXX38dLVu2xNGjR7X216tXD6+//rrWvjZt2uDWrVsVFlO7du1gZmaG8ePHIzIyEr/99lu5jjt27Bi8vb1LtGADAgKQk5NTokX5bJct8PRzAJD1Wbp16wYXFxeEh4fj4sWLiIuLK7OrsjhGHx8fWFtbw8TEBKampli4cCEePHiAlJSUcl938ODB5S47a9Ys+Pn54e2330ZkZCTWrFmD1q1bl/t4IiY5Mhh2dnaoXr06bty4Ua7yDx48AAA4ODiUeM/R0VHzfrHatWuXKKdWq/H48WMdoi2di4sLjhw5Ant7e0yePBkuLi5wcXHB559//sLjHjx4UObnKH7/Wc9/luLxSzmfRZIkjBkzBl999RXWr1+P5s2bo2vXrqWWjY2NRe/evQE8nf36888/Iy4uDvPnz5d93dI+54tiDAgIQG5uLurVq8exOJKNSY4MhomJCby9vXH27NkSE0dKU/xFf/fu3RLv3blzB3Z2dhUWm7m5OQAgLy9Pa//z434A0LVrV3z33Xd49OgRYmJi4OXlhenTp2P79u1lnr927dplfg4AFfpZnhUQEIC0tDSsX78eY8aMKbPc9u3bYWpqigMHDuCtt95C586d4eHhodM1S5vAU5a7d+9i8uTJaNeuHR48eICZM2fqdE16dTHJkUGZO3cuhBAYN25cqRM18vPz8d133wEAevbsCQCaiSPF4uLikJSUBG9v7wqLq3iG4IULF7T2F8dSGhMTE3h6emLt2rUAgISEhDLLent749ixY5qkVmzz5s2oXr16pU2vr1+/PmbNmoUBAwbA39+/zHKSJKFatWowMTHR7Hv8+DG2bNlSomxFtY4LCwvx9ttvQ5IkHDx4EMuXL8eaNWuwZ8+elz43vTp4nxwZFC8vL4SEhGDSpEno0KEDJk6cCDc3N+Tn5+PcuXMIDQ3Fa6+9hgEDBsDV1RXjx4/HmjVroFKp4Ovri5s3b2LBggVwcnLC+++/X2Fx9evXD7a2tggMDMSSJUtQrVo1bNq0CcnJyVrl1q9fj2PHjsHPzw8NGzZEbm6uZgajj49PmecPCgrCgQMH0KNHDyxcuBC2trbYunUrvv/+e6xatQrW1tYV9lmet2LFir8s4+fnh88++wwjRozA+PHj8eDBA3zyySel3ubRunVrbN++HTt27ECTJk1gbm6u0zhaUFAQTp06hUOHDqFevXr44IMPcPLkSQQGBsLd3R2NGzeWfU56Bel75gtRaRITE4W/v79o2LChMDMzEzVq1BDu7u5i4cKFIiUlRVOusLBQrFy5UjRv3lyYmpoKOzs7MWrUKJGcnKx1vm7dugk3N7cS1/H39xfOzs5a+1DK7EohhIiNjRWdO3cWNWrUEPXr1xdBQUHiyy+/1JpdGR0dLf7+978LZ2dnoVarRe3atUW3bt3E/v37S1zj2dmVQghx8eJFMWDAAGFtbS3MzMxE27ZtRUREhFaZ4lmIu3bt0tp/48YNAaBE+ec9O7vyRUqbIRkeHi5cXV2FWq0WTZo0EcuXLxdhYWFan18IIW7evCl69+4tLC0tBQDNz7es2J99r3h25aFDh4RKpSrxM3rw4IFo2LCh6Nixo8jLy3vhZyASQghJiGfu5CQiIlIQjskREZFiMckREZFiMckREZFiMckREZHBKSgowIcffojGjRvDwsICTZo0wZIlSzQPVC8v3kJAREQGZ+XKlVi/fj0iIyPh5uaG+Ph4jBkzBtbW1pg2bVq5z8MkR0REBic6OhoDBw6En58fgKcPZNi2bRvi4+NlnYdJTo+Kiopw584dWFpaynrUERHRs4QQyMzMhKOjI1SqqhmFys3NfeHyUWURQpT4vlOr1SUeLPDGG29g/fr1+O9//4vmzZvj/PnzOH36NIKDg2VfkPQkOTlZAODGjRu3CtmefwhCZXn8+LFAteo6xVizZs0S+56/6V8IIYqKisQ///lPIUmSqFatmpAkSSxbtkx2rGzJ6ZGlpSUAwKyVPyQTMz1HQ4bqb2OG6zsEMnAFudk4Pu//NN8ple3JkydAQQ7UbmMAOd9dhU+QdTkCycnJsLKy0uwu7fFwO3bswFdffYWvv/4abm5uSExMxPTp0+Ho6PjC56w+j0lOj4qb7JKJGZMclcnUoqa+QyAjUeXDHtXMIJmUTFBlEf8Lz8rKSivJlWbWrFn45z//ieHDn/6S17p1a9y6dQvLly9nkiMioiogqZ5ucsqXU05OTonxRRMTE95CQEREVUSSnm5yypfTgAEDsHTpUjRs2BBubm44d+4cPvvssxeuXl8aJjkiItJNJbbk1qxZgwULFmDSpElISUmBo6Mj3n33XSxcuFBWiExyRESkm0psyVlaWiI4OFj+LQPPYZIjIiIdyWzJ6eFJkkxyRESkm0psyVUUJjkiItJNJY7JVRQmOSIi0o0RtOS41A4RESkWW3JERKQbdlcSEZFiGUF3JZMcERHphi05IiJSLEmSmeTYkiMiImOhkp5ucspXMSY5IiLSDbsriYhIsTjxhIiIFIstOSIiUiy25IiISLHYkiMiIsViS46IiBSLLTkiIlIstuSIiEi5DH9lcC61Q0REisWWHBER6YbdlUREpFh8QDMRESkWZ1cSEZFisbuSiIgUiy05IiJSLLbkiIhIsdiSIyIixWJLjoiIlEqSJEhMckREpERMckREpFzS/zY55asYkxwREemELTkiIlIsY0hyXIWAiIgUiy05IiLSiTG05JjkiIhIJ0xyRESkXJxdSURESsWWHBERKdbTp3rJSXKVF0tZmOSIiEgnEmS25PSQ5ZjkiIhIJ+yuJCIi5eLEEyIiUiyZLTnBlhwRERkLud2V8sbvKgYf60VERDopTnJytvJq1KhRqcdPnjxZVoxsyRERkW4qcUwuLi4OhYWFmteXLl1Cr169MHToUBkXZJIjIiIdVWZ3ZZ06dbRer1ixAi4uLujWrVu5zwEwyRERkY50TXIZGRla+9VqNdRqdZnHPXnyBF999RVmzJghe1yPY3JERFSlnJycYG1trdmWL1/+wvL79u3Dw4cPERAQIPtabMkREZFOdG3JJScnw8rKSrP/Ra04AAgLC4Ovry8cHR1lx8gkR0REOtE1yVlZWWkluRe5desWjhw5gj179ugUI5McERHppgqeeBIREQF7e3v4+fnJPxhMcmQATExU+PDdfhjezwN1a1vhXloGtnwXgxUbf4QQQt/hkYGoXcMUYzyd0KFhLZiZSLjzKBefn7iBa2k5+g7tlVXZN4MXFRUhIiIC/v7+qFZNt3TFJEd690FAL4wd8gbGLdyCK9fvooNbQ2xYNAoZmblYu+2EvsMjA1DTzAT/erMVLvyRgaAfruLh43w4WJkj60nhXx9Mlaayk9yRI0dw+/ZtvPPOO3JD02CSI73zbNMYB05eQNTpywCA23f/xFt9PdC+VUM9R0aGYoi7A1KzniD4xA3NvpTMJ3qMiIDKT3K9e/d+6d4c3kJAehedeB09XndF04b2AIDWzevDq10T/PjzZT1HRobC09kG11KzMbdXU2z1d8fqIW7o07LOXx9IlUvSYatibMm9gCRJ2Lt3L9588019h6Jon0QchlVNC5zf+yEKCwVMTCQErT2AnVFn9R0aGYh6Vmr0a2WPvRfuYUfCHTS3r4F3uzgjv7AIx/77QN/hvbL4gOZy+uWXX2BiYoK+ffvKPrZRo0YIDg6u+KDKad26dWjcuDHMzc3RoUMHnDp1Sm+xGKuhfTrg7X4dETAvEl4jVmLswi2YPtobIwd46js0MhCSBFxPy8bm2N/x24McRCWl4sekFPRrVVffob3SKvMBzRXFIJJceHg4pkyZgtOnT+P27dv6DqfcduzYgenTp2P+/Pk4d+4cunbtCl9fX6P6DIZg2fQ38UnEYez68SwuX7uDbd/HYc3WY5g1ppe+QyMDkZ6Tj9vpj7X2Jafnoo6lmZ4iIgCQIDPJ6aG/Uu9JLjs7Gzt37sTEiRPRv39/bNq0qUSZ/fv3w8PDA+bm5rCzs8OgQYMAAN27d8etW7fw/vvva/2WsGjRIrRr107rHMHBwWjUqJHmdVxcHHr16gU7OztYW1ujW7duSEhIkBX7Z599hsDAQIwdOxYtW7ZEcHAwnJycEBISIus8rzoLczMUiSKtfYVFAiqV3qsnGYgr97JQv5aF1r76tcyRmpmnp4gIYEuuXHbs2AFXV1e4urpi1KhRiIiI0JpN8/3332PQoEHw8/PDuXPncPToUXh4eAAA9uzZgwYNGmDJkiW4e/cu7t69W+7rZmZmwt/fH6dOnUJMTAyaNWuGfv36ITMzs1zHP3nyBGfPnkXv3r219vfu3Ru//PJLqcfk5eUhIyNDayPgh58uYk5gH/R9ww0NHWzxfz3aYOqoHth/7Ly+QyMDse/CPbSwr4G33B3gYKVGt6a10bdlHRy4nKLv0F5tnHjy18LCwjBq1CgAQN++fZGVlYWjR4/Cx8cHALB06VIMHz4cixcv1hzTtm1bAICtrS1MTExgaWmJevXqybpuz549tV5v2LABNjY2OHnyJPr37/+Xx6elpaGwsBB162qPCdStWxf37t0r9Zjly5drfQ56asbKXQia1B+fzxuGOjY1cTf1EcK++RnLQg/qOzQyEL+mZuPjH68hwLMB3u5QH/cz8xD6y22c+JWTTvTJGCae6DXJXb16FbGxsZpnklWrVg3Dhg1DeHi4JsklJiZi3LhxFX7tlJQULFy4EMeOHcP9+/dRWFiInJwc2eNpz/+jCSHK/IecO3cuZsyYoXmdkZEBJycn+cErTFZOHmZ9shuzPtmt71DIgMXdfoi42w/1HQY9g0nuL4SFhaGgoAD169fX7BNCwNTUFOnp6bCxsYGFhcULzlA6lUpV4gbC/Px8rdcBAQFITU1FcHAwnJ2doVar4eXlhSdPyneDqZ2dHUxMTEq02lJSUkq07or91ZpJRERUsfQ2JldQUIDNmzfj008/RWJiomY7f/48nJ2dsXXrVgBAmzZtcPTo0TLPY2ZmprVEOvB0Rdl79+5pJbrExEStMqdOncLUqVPRr18/uLm5Qa1WIy0trdzxm5mZoUOHDjh8+LDW/sOHD6Nz587lPg8RkbGSJPlbVdNbS+7AgQNIT09HYGAgrK2ttd4bMmQIwsLC8N577yEoKAje3t5wcXHB8OHDUVBQgIMHD2L27NkAnt4n99NPP2H48OFQq9Wws7ND9+7dkZqailWrVmHIkCGIiorCwYMHtZZ2aNq0KbZs2QIPDw9kZGRg1qxZsluNM2bMwOjRo+Hh4QEvLy+Ehobi9u3bmDBhwsv/gIiIDNzTxCWnu7ISgymD3lpyYWFh8PHxKZHgAGDw4MFITExEQkICunfvjl27dmH//v1o164devbsiTNnzmjKLlmyBDdv3oSLiwvq1Hn6mJ+WLVti3bp1WLt2Ldq2bYvY2FjMnDlT6xrh4eFIT0+Hu7s7Ro8ejalTp8Le3l7WZxg2bBiCg4OxZMkStGvXDj/99BN++OEHODs76/ATISIyMnJbcXpIcpLgWiZ6k5GRAWtra6hbj4NkwptaqXQ93/2HvkMgA5f/OAuHZ3jj0aNH5V6M9GUUf3e5TNsNE3WNch9XmJeN658PrrI4AQO4hYCIiIyT3HG2V2pMjoiIjJtKJUGlKn/mEjLKVhQmOSIi0glbckREpFi8GZyIiBSLLTkiIlIstuSIiEixmOSIiEix2F1JRESKVbwyuJzyVY1JjoiIdGIMLTm9rwxORERUWdiSIyIinXDiCRERKZYxdFcyyRERkU7YkiMiIsViS46IiBSLLTkiIlIumS05fawMziRHREQ6YUuOiIgUi2NyRESkWGzJERGRYrElR0REisWWHBERKRaTHBERKRa7K4mISLGMoSXHpXaIiEix2JIjIiKdsLuSiIgUyxi6K5nkiIhIJxJktuQqLZKyMckREZFOVJIElYwsJ6dsRSlXklu9enW5Tzh16lSdgyEiIuOhmDG5f//73+U6mSRJTHJERK+Iyh6T++OPPzBnzhwcPHgQjx8/RvPmzREWFoYOHTqU+xzlSnI3btyQFRgRESmfSnq6ySlfXunp6ejSpQt69OiBgwcPwt7eHtevX0etWrVkxajzmNyTJ09w48YNuLi4oFo1Du0REb1yJJmtMxlFV65cCScnJ0RERGj2NWrUqPwn+B/ZN4Pn5OQgMDAQ1atXh5ubG27fvg3g6VjcihUrZAdARETGqXhMTs4GABkZGVpbXl5eiXPv378fHh4eGDp0KOzt7eHu7o6NGzfKjlF2kps7dy7Onz+PEydOwNzcXLPfx8cHO3bskB0AEREZJ0mHPwDg5OQEa2trzbZ8+fIS5/7tt98QEhKCZs2a4ccff8SECRMwdepUbN68WVaMsvsZ9+3bhx07dqBTp05azdRWrVrh+vXrck9HRERGStcxueTkZFhZWWn2q9XqEmWLiorg4eGBZcuWAQDc3d1x+fJlhISE4B//+Ef5r1n+8J5KTU2Fvb19if3Z2dl6uZudiIj0o3h2pZwNAKysrLS20pKcg4MDWrVqpbWvZcuWmiGy8pKd5Dp27Ijvv/9e60MCwMaNG+Hl5SX3dEREZKR0HZMrjy5duuDq1ata+/773//C2dlZVoyyuyuXL1+Ovn374sqVKygoKMDnn3+Oy5cvIzo6GidPnpR7OiIiMlKV+cST999/H507d8ayZcvw1ltvITY2FqGhoQgNDZUXo6zSADp37oyff/4ZOTk5cHFxwaFDh1C3bl1ER0fLukGPiIioLB07dsTevXuxbds2vPbaa/joo48QHByMkSNHyjqPTje4tW7dGpGRkbocSkREClHZj/Xq378/+vfvL++g5+iU5AoLC7F3714kJSVBkiS0bNkSAwcO5E3hRESvEEUutXPp0iUMHDgQ9+7dg6urK4Cng4F16tTB/v370bp16woPkoiIDI8xPKBZ9pjc2LFj4ebmht9//x0JCQlISEhAcnIy2rRpg/Hjx1dGjEREZICKJ57I2aqa7Jbc+fPnER8fDxsbG80+GxsbLF26FB07dqzQ4IiIyHBJkLcQqj7upJbdknN1dcX9+/dL7E9JSUHTpk0rJCgiIjJ8ut4MXpXK1ZLLyMjQ/H3ZsmWYOnUqFi1ahE6dOgEAYmJisGTJEqxcubJyoiQiIoNTmUvtVJRyJblatWppZWAhBN566y3NPiEEAGDAgAEoLCyshDCJiMjQKGZ25fHjxys7DiIiMkKG/sjiciW5bt26VXYcRERkZBTTkitNTk4Obt++jSdPnmjtb9OmzUsHRUREhk8xY3LPSk1NxZgxY3Dw4MFS3+eYHBHRq8EYWnKybyGYPn060tPTERMTAwsLC0RFRSEyMhLNmjXD/v37KyNGIiIyQJIOW1WT3ZI7duwYvv32W3Ts2BEqlQrOzs7o1asXrKyssHz5cvj5+VVGnEREZGAqc6mdiiK7JZedna1ZGdzW1hapqakAnq5MkJCQULHRERERvQSdnnhSvFpru3btsGHDBvzxxx9Yv349HBwcKjxAIiIyTJW5MnhFkd1dOX36dNy9excAEBQUhD59+mDr1q0wMzPDpk2bKjo+IiIyUMYw8UR2knt2VVZ3d3fcvHkT//nPf9CwYUPY2dlVaHBERGS4jGGpnZde5bR69epo3759RcRCRERGxBgmnpQryc2YMaPcJ/zss890DoaIiIyHYlpy586dK9fJ9NHfqgS3T3wCKysrfYdBREYqIyMDdcvfFqkwihmT4wOaiYjoeSrIm6Ivezp/BXjpMTkiIno1KaYlR0RE9DxJ5gOaDXZMjoiI6HmKXIWAiIgIYHclEREpmDG05HSa7LJlyxZ06dIFjo6OuHXrFgAgODgY3377bYUGR0REhssYnl0pO8mFhIRgxowZ6NevHx4+fKhZJLVWrVoIDg6u6PiIiMhAFT/xRM5W5THKPWDNmjXYuHEj5s+fDxMTE81+Dw8PXLx4sUKDIyIiehmyx+Ru3LgBd3f3EvvVajWys7MrJCgiIjJ8xnAzuOxrNm7cGImJiSX2Hzx4EK1ataqImIiIyAgYw5ic7JbcrFmzMHnyZOTm5kIIgdjYWGzbtg3Lly/Hl19+WRkxEhGRAVJB5ioEMIJbCMaMGYOCggLMnj0bOTk5GDFiBOrXr4/PP/8cw4cPr4wYiYjIAClmFYLnjRs3DuPGjUNaWhqKiopgb29f0XEREZGBM4b75F7qZnCuBE5E9Op6+uxKOU88qcRgyiA7yTVu3PiFj2b57bffXiogIiIyDorsrpw+fbrW6/z8fJw7dw5RUVGYNWtWRcVFREQGTpHdldOmTSt1/9q1axEfH//SARERkXGQ/vdHTvmqVmH35vn6+mL37t0VdToiIjJwxS05OVtVq7BVCL755hvY2tpW1OmIiMjAKbK70t3dXWviiRAC9+7dQ2pqKtatW1ehwRERkeFS5Hpyb775ptZrlUqFOnXqoHv37mjRokVFxUVERAZOcS25goICNGrUCH369EG9evUqKyYiIjICxnALgayJJ9WqVcPEiRORl5dXWfEQERFh0aJFmu7Q4k2XxpXs7kpPT0+cO3cOzs7Osi9GRETKIXchVLmLprq5ueHIkSOa18+uYVpespPcpEmT8MEHH+D3339Hhw4dUKNGDa3327RpIzsIIiIyPpU9JletWrWXHhord5J75513EBwcjGHDhgEApk6dqnlPkiQIISBJEgoLC18qICIiMhJy14j7X9mMjAyt3Wq1Gmq1ukTxX3/9FY6OjlCr1fD09MSyZcvQpEkTWSGWO8lFRkZixYoVuHHjhqwLEBGRMqkgyVojrrisk5OT1v6goCAsWrRIa5+npyc2b96M5s2b4/79+/j444/RuXNnXL58GbVr1y73Ncud5IQQAMCxOCIiAqD77Mrk5GRYWVlp9pfWivP19dX8vXXr1vDy8oKLiwsiIyMxY8aMcl9T1picPm7kIyIiw6TrmJyVlZVWkiuPGjVqoHXr1vj1119lHScryTVv3vwvE92ff/4pKwAiIjJOlT278ll5eXlISkpC165dZR0nK8ktXrwY1tbWsi5ARETKVJk3g8+cORMDBgxAw4YNkZKSgo8//hgZGRnw9/eXFaOsJDd8+HDY29vLugARESmTCjJbcjImqfz+++94++23kZaWhjp16qBTp06IiYmRPS+k3EmO43FERPSsymzJbd++XX5ApZA9u5KIiAh4+lxIOc+GrLAFTGUod5IrKiqqzDiIiMjIKHKpHSIiIuDpA0x0eOBJlWKSIyIinVTlLQS60kcXKRERUZVgS46IiHRm6PPumeSIiEgnxrAyOJMcERHphLMriYhIsRR1nxwREdGz2JIjIiLF4n1yRESkWGzJERGRYnFMjoiIFIstOSIiUiyOyRERkWLxZnAiIlIsFSRZq33LKVtRmOSIiEgnbMkREZFiSf/7I6d8VeNSO0REpFhsyRERkU7YXUlERIolyZx4oo/uSiY5IiLSCVtyRESkWExyRESkWJxdSVQOoetD0NG9DextrWBva4Vub3jhx6iD+g6LDAzrieFRSfK3Ko+x6i9JpK1+gwb4aNkK/BwTj59j4tG9R08MHTQQVy5f1ndoZEBYTwyPpMOfKo9RCCGq/KoEAMjIyIC1tTXuP3gEKysrfYdjUBztbbFsxb8Q8E6gvkMhA8Z68lRGRgbq1rbGo0dV811S/N31XfwN1KhpWe7jsrMyMcCjcZXFCXBMjgxMYWEhdn+zC9nZ2fDs5KXvcMhAsZ4YhqerEMgZk6t6THJkEC5dvIjuXb2Qm5uLmjVrYsc3e9GyVSt9h0UGhvXEsMgdZ+OYnIGRJAn79u3TdxivhOaurjgTn4iTp2Mw7t2JGPeOP5KuXNF3WGRgWE8MizGMyRlEkvvll19gYmKCvn37yj62UaNGCA4OrvigyuGnn37CgAED4OjoyIT4kszMzODStCk6eHjgo6XL0bpNW6xd87m+wyIDw3piWIrvk5OzVTWDSHLh4eGYMmUKTp8+jdu3b+s7nHLLzs5G27Zt8cUXX+g7FMURQiAvL0/fYZCBYz3RL0mHrarpPcllZ2dj586dmDhxIvr3749NmzaVKLN//354eHjA3NwcdnZ2GDRoEACge/fuuHXrFt5//31IkgTpf78mLFq0CO3atdM6R3BwMBo1aqR5HRcXh169esHOzg7W1tbo1q0bEhISZMXu6+uLjz/+WBMP6Wbhh/Nw+vQp3Lp5E5cuXkTQgvn46eQJDB8xUt+hkQFhPTE8KkhQSTK2V7G7cseOHXB1dYWrqytGjRqFiIgIPHtXw/fff49BgwbBz88P586dw9GjR+Hh4QEA2LNnDxo0aIAlS5bg7t27uHv3brmvm5mZCX9/f5w6dQoxMTFo1qwZ+vXrh8zMzAr/jMXy8vKQkZGhtRGQcv8+AgNGo42bK/r18UZc7Bns/z4K3j699B0aGRDWE9KF3mdXhoWFYdSoUQCAvn37IisrC0ePHoWPjw8AYOnSpRg+fDgWL16sOaZt27YAAFtbW5iYmMDS0hL16tWTdd2ePXtqvd6wYQNsbGxw8uRJ9O/f/2U+UpmWL1+u9TnoqfUbw/QdAhkB1hPDI7cL8pXrrrx69SpiY2MxfPhwAEC1atUwbNgwhIeHa8okJibC29u7wq+dkpKCCRMmoHnz5rC2toa1tTWysrIqdUxw7ty5ePTokWZLTk6utGsREVU6IxiU02tLLiwsDAUFBahfv75mnxACpqamSE9Ph42NDSwsLGSfV6VS4fkHueTn52u9DggIQGpqKoKDg+Hs7Ay1Wg0vLy88efJEtw9TDmq1Gmq1utLOT0RUlfiA5hcoKCjA5s2b8emnnyIxMVGznT9/Hs7Ozti6dSsAoE2bNjh69GiZ5zEzM0NhYaHWvjp16uDevXtaiS4xMVGrzKlTpzB16lT069cPbm5uUKvVSEtLq7gPSESkdHJvH3iVWnIHDhxAeno6AgMDYW1trfXekCFDEBYWhvfeew9BQUHw9vaGi4sLhg8fjoKCAhw8eBCzZ88G8PQ+uZ9++gnDhw+HWq2GnZ0dunfvjtTUVKxatQpDhgxBVFQUDh48qPWstKZNm2LLli3w8PBARkYGZs2aJbvVmJWVhWvXrmle37hxA4mJibC1tUXDhg1f4qdDRGT4OCb3AmFhYfDx8SmR4ABg8ODBSExMREJCArp3745du3Zh//79aNeuHXr27IkzZ85oyi5ZsgQ3b96Ei4sL6tSpAwBo2bIl1q1bh7Vr16Jt27aIjY3FzJkzta4RHh6O9PR0uLu7Y/To0Zg6dSrs7e1lfYb4+Hi4u7vD3d0dADBjxgy4u7tj4cKFcn8cRETGxwjG5LgKgR5xFQIiqgj6WoXg+Plk1LQs//WyMjPQo60TVyEgIiLDJ/dRXfp4rBeTHBER6YRjckREpFxVOCa3fPlySJKE6dOnyzqOLTkiItJJVd0nFxcXh9DQULRp00b2sWzJERGRTqpiqZ2srCyMHDkSGzduhI2NjezjmeSIiEgnuvZWPv+g+hctlzR58mT4+flpnmcsF5McERHpRscs5+TkpHlmsLW1NZYvX17q6bdv346EhIQy3y8PjskREVGVSk5O1rpPrrRn+iYnJ2PatGk4dOgQzM3Ndb4WkxwREelE14knVlZWf3kz+NmzZ5GSkoIOHTpo9hUWFuKnn37CF198gby8PJiYmPzlNZnkiIhIJ5V5M7i3tzcuXryotW/MmDFo0aIF5syZU64EBzDJERGRjirzZnBLS0u89tprWvtq1KiB2rVrl9j/IkxyRESkGyN45AmTHBER6aSqF009ceKE7GOY5IiISCd8QDMRESmWEfRWMskREZGOjCDLMckREZFOqnpMThdMckREpBOOyRERkWIZQW8lkxwREenICLIckxwREemEY3JERKRcchdC1UNLjuvJERGRYrElR0REOjGCITkmOSIi0pERZDkmOSIi0gknnhARkWLxZnAiIlIsI+itZJIjIiIdGUGWY5IjIiKdcEyOiIgUS4LMMblKi6RsTHJERKQTI+itZJIjIiLdcHYlEREpmOG35ZjkiIhIJ2zJERGRYhl+O45JjoiIdGQMLTkutUNERIrFlhwREemEN4MTEZFyGcGgHJMcERHpxAhyHJMcERHpxhgmnjDJERGRTjgmR0REymUE/ZVMckREpBMjyHFMckREpBuOyRERkYLJG5PjA5qJiMhoGENLjo/1IiIixWJLjoiIdGIMLTkmOSIi0gnvkyMiIsUyhpYcx+SIiEix2JIjIiKd8GZwIiJSLiPIckxyRESkE048ISIixeLEEyIiUixJh628QkJC0KZNG1hZWcHKygpeXl44ePCg7BiZ5IiISDeVmOUaNGiAFStWID4+HvHx8ejZsycGDhyIy5cvywqR3ZVERKSTyhyTGzBggNbrpUuXIiQkBDExMXBzcyv3eZjk9EgIAQDIzMjQcyREZMyKv0OKv1Oq7LqZGbLG2TIzn8aZ8dx3nlqthlqtLvO4wsJC7Nq1C9nZ2fDy8pIXpCC9SU5OFgC4cePGrUK25OTkKvnuevz4sahXr55OMdasWbPEvqCgoFKvc+HCBVGjRg1hYmIirK2txffffy87VkmIKk79pFFUVIQ7d+7A0tISkj6mHRmgjIwMODk5ITk5GVZWVvoOhwwQ60hJQghkZmbC0dERKlXVTLXIzc3FkydPZB8nhCjxfVdWS+7Jkye4ffs2Hj58iN27d+PLL7/EyZMn0apVq3Jfj0mODEpGRgasra3x6NEjfoFRqVhHXl0+Pj5wcXHBhg0byn0MZ1cSEZFREEIgLy9P1jGceEJERAZn3rx58PX1hZOTEzIzM7F9+3acOHECUVFRss7DJEcGRa1WIygo6IUzrejVxjryarh//z5Gjx6Nu3fvwtraGm3atEFUVBR69eol6zwckyMiIsXimBwRESkWkxwRESkWkxwRESkWkxwRESkWkxwRESkWkxwpWlFRkb5DICI94n1ypFhFRUVQqVS4f/8+0tLS8PDhQ3Tu3JnPCSWN4jpSWFgIExMTfYdDlYAtOVKk4i+vCxcuwMvLC8OGDUPXrl3h4+OD0NBQfYdHBqC4jly5cgWTJk3C3bt39R0SVQImOVKk4hbc3//+dwwdOhR79+7Ff/7zH9jY2CA8PByzZ8/Wd4ikZyqVCr/99hv69u2LjRs3YuzYsUhNTdV3WFTBmORIsa5fvw5JkjBp0iQ0a9YMzZs3x/r16+Hj44Njx45h8eLF+g6R9Ojx48dYv349PD09cfjwYVy8eBEjRoxgolMYJjlSLLVajZycHNy6dQvA09WF7ezsMHPmTHTr1g1RUVH4+eef9Rwl6YskSXBzc8Nbb70Fb29vHD16FFevXmWiUxgmOVIsJycnmJubY9u2bQAAExMTFBYWolatWvjwww+RkpKCffv26TdI0htzc3MMHToUQ4cOBQA0a9YMhw8fLpHoCgsLcf78eX2GSi+BSY4USQgBe3t7fPHFF9i4cSOWL18O4Ok4jBACNjY26N+/P/7zn//oOVLSp+rVqwN4Wl8AwNXVFYcOHdIkuj/++ANTpkzBrFmz8OjRI32GSjriLQSkSMW3CfTr1w///ve/8f777yM3NxczZ86EpaUlAODOnTuoW7cuhBC8reAVV/zvL4RAixYtcPjwYfj6+sLNzQ2PHz/GL7/8Amtraz1HSbpgkiOjtmrVKjg7O2PYsGFllpkwYQJq1qyJiRMn4syZM7C1tYW5uTmioqIQExPDBKdw5akjxYrrgqurq2ZCSkJCAtzc3Co7TKok7K4ko5aUlIRRo0bh22+/LbOMqakpxowZg9jYWDRt2hQ5OTkwMTFBdHQ0v7xeAeWpI88SQmDFihXYsWMHjhw5wjpi5LhoKhm9adOmITQ0FNu2bcObb75Zapnnn2xRUFCAatXYkfGqKE8dKZafn4/vv/8eLVq0QIsWLaomQKo0/L+cjJIQAkIIqFQqfPTRR3j48CHGjx8PU1NT+Pn5lSivUqm0/stHOCmf3DpSzNTUFAMHDmQ3tkKwu5KMlkqlwu7du9G7d29kZmYiPT0db7/99gtvCyj+4uIX2KtBlzoCsH4oCZMcGSVJkhAfH4/Ro0dj7NixWL16Nc6dO4fBgwdjxIgRvP+NWEcIALsryYjdunULLi4uGDJkCGrVqoUGDRogNDQURUVF8Pf3x/bt2+Hr66vvMEmPWEeILTkyKs/Ok8rLy9O6mbugoACmpqaYPHkyMjMz4efnhwMHDugjTNIj1hF6FpMcGYXiL65nx0oGDRqENm3aYPLkyXj48KFmtmTt2rUxYsQITJs2DS4uLnqJl6oe6wiVhrcQkMErfiJJdHQ0oqOjkZ2djVatWmHw4MH46quvEBISggYNGuDzzz9HYWEhQkJCcPLkSRw+fBjm5ub6Dp+qAOsIlYVjcmTwJEnC7t27ERgYCF9fX2RlZWHz5s04evQo1q1bh5ycHERERMDR0RHNmjXDgwcP+OX1imEdobKwJUcG79dff0WvXr0wZ84cTJw4EVeuXEHnzp0xatQofPHFFygqKgIAHDhwADVq1EDTpk3h7Oys56ipKrGOUFmY5MhgFT+l5MSJE/jggw9w9uxZ3Lp1C127dkW/fv2wfv16AMCZM2fg6emp52hJH1hH6K9w4gkZhOLftIufUgEAKSkpAJ52RdWqVQsJCQno2rUrfH19sXbtWgBAQkICtm7dil9//VU/gVOVYR0hXTDJkUFQqVT473//i/DwcEiShF27dqFv3764f/8+HBwccOHCBXTs2BG+vr7YsGGD5rFcW7ZsQVJSEmrXrq3nT0CVjXWEdMGJJ2QwfvjhB8yYMQNxcXEIDQ1FREQE6tati7p16yI0NBSDBw9GzZo1ERcXB7VajcjISGzatAmnTp2Cra2tvsOnKsA6QnJxTI4MyuDBg/Htt99i1KhR2LRpk9a9T19//TVmzZoFIQRsbW1hZmaG8PBwtGvXTr9BU5ViHSE5mORI755dmXvMmDG4d+8eDh06hDVr1mDSpElaZZKTk5GWlgZTU1M4Ojryt/NXBOsI6YrdlaRXz97Em5KSohlvWbFiBaZMmQIAmDRpkuYLrqCgAO7u7voMmaoY6wi9DCY50pviL6/du3djwoQJCAwMROPGjdGmTRv885//BABMnToVQgiMHDkSa9euxb59+3D06FFYWlpyOZRXAOsIvTRBVMWKioo0f4+JiRE2NjZiw4YNoqCgoETZTz75REiSJDp27CgsLS3F2bNnqzJU0hPWEaooHJOjKhMbG4vXX38dwP//DX3VqlU4efIkDhw4oPmtu7CwUGvl7uPHj+OPP/5Aly5d0LhxY73ETlWDdYQqGrsrqUp89dVXiIyMxM6dO2FjY6P5skpLS8PDhw9RVFSk+dIq/m90dDQ6dOiAHj166C1uqjqsI1QZeDM4VYm2bdviyy+/hI2NDf744w/NfgcHB1y+fBnXrl3TKp+Xl4dt27Zxra9XCOsIVQr99paS0u3cuVOkp6drXp8/f1506tRJhISEaPZ17txZuLq6ikuXLomsrCzx+PFjMXfuXNGgQQNx48aNqg+aqhTrCFUmtuSo0ly6dAkLFizAqFGjkJWVBeDpOEv9+vWxbds2hIWFAQB27twJBwcHvPHGG/D09ETv3r0RFhaG/fv3o1GjRnr8BFTZWEeosnHiCVWaJ0+e4Ouvv0ZoaCjs7OywZcsWWFtb48KFC/jXv/6F69ev491334W/vz8AIDIyEn/++ScsLCzQp08fTiB4BbCOUGVjkqNK8ezst+LnB9rZ2SEiIgI1a9bE+fPn8cknn+C3337DmDFjMHbsWD1HTFWNdYSqArsrqVKoVE+r1k8//YSYmBikp6dj9+7dGDNmDDIyMtC2bVvMnDkTTZo0wZYtWxASEqLniKmqsY5QVWCSo0ohSRJ+/PFHdO/eHU2bNsWCBQswadIkJCUlYfTo0ZovsVmzZsHGxgbffvstHj16pO+wqQqxjlBVYHclVTghBAoKCjBhwgQIIRAeHg7g6aKX4eHh+PTTT9G6dWuEh4ejZs2auHTpEmxtbeHo6KjnyKmqsI5QVeHN4FThJEmCqakpcnNzcffuXc1+lUqFsWPH4syZMwgLC9N0T7322mt6jJb0gXWEqgq7K6lSCCHg6emJzMxMxMTEoLCwUPNely5d4O7ujpo1a7L76RXGOkJVgUmOXlpxj/e1a9eQmJiI2NhYSJKEgIAAPHnyBB9++CGio6M15a5cuYLu3btj06ZNcHJy0mfoVEVYR0hfOCZHL0X87yG6e/fuxfvvvw87Oztcu3YNffr0wbx58+Dg4AAfHx+o1WoIIeDg4IAjR44gISEBLVu21Hf4VAVYR0if2JKjlyJJEk6fPo133nkH8+bNQ3x8PCIiIrBr1y6cOXMG9vb2OH78OCZPngxPT0+4urri7Nmz/PJ6hbCOkD6xJUc6K76Z9+OPP8bly5exbds2XL9+HX379kWPHj0QGhoKIQTy8/NhZmYG4OnsueL7o0j5WEdI31iTSLbi34t+//13AMDNmzfh6uqKoqIidOvWDT179sSGDRsAAN988w327NmDgoICAOBKza8I1hEyFExyJJskSdi1axcaN26MtLQ0dOzYEatXr0bdunUxdOhQrFu3TvNFdfDgQZw8eVIzc45fYK8G1hEyFExyVG7Fv52npaXhl19+QXBwMOzs7NC/f394e3tDpVJh9OjRMDExQWZmJubNm4eDBw9i+vTpUKvVeo6eqgLrCBka3gxOZSqeFVdMkiTExsZiypQpEEIgICAAAFC/fn2MHz8eeXl56NKlC9q3bw+VSoUbN27ghx9+gKurq54+AVU21hEydExyVKriwf8HDx7gzp07yM3NRceOHZGVlQVJknDp0iWtyQG9evVC27ZtcejQIVy9ehVNmjRBjx49uNaXgrGOkDHg7EoqofjL69KlSxg7dix+//13ZGdnw8fHB7t27cLp06cxefJkqFQq7NmzB40bNy7xGz0pG+sIGQuOyZGW4i+v8+fPo1OnTvDy8sLGjRsxbdo0nDhxAoGBgXjjjTewdOlS2NraYsyYMbh58yYkSdLMjiNlYx0hoyKInvPrr78Kc3Nz8eGHH2r2PXnyRIwaNUq4urqK3NxcIYQQ+/btE97e3qJnz57i+vXr+gqX9IB1hIwFW3KkpXipE0tLS9SpU0ez39TUFB07doSZmZnmgbkDBw7EtGnT8OjRI0ydOhUFBQWa2XWkXKwjZEw48YS0qFQqvPfee8jJycHXX3+NrKwszJs3D6mpqViwYAHmzJkDe3t7zfjKgAEDYGJigtdeew3VqrE6vQpYR8iYcOIJlerevXtYunQpEhIS0KVLF2zbtg1///vfsXr1agD//34oTiR4dbGOkDFgkqMy3b17F8uWLcPu3btRv359xMXFAQAKCgr4GzkBYB0hw8cxOSqTg4MDPvzwQwwZMgQmJiZYuXIlAKBatWooKirSc3RkCFhHyNCxJUd/qbhb6ty5c/D29sbixYv1HRIZGNYRMlRsydFfqlevHubPn49mzZrhl19+wYMHD/QdEhkY1hEyVGzJUbndv38fAFC3bl09R0KGinWEDA2THBERKRa7K4mISLGY5IiISLGY5IiISLGY5IiISLGY5IiISLGY5IiISLGY5IiISLGY5IgqwKJFi9CuXTvN64CAALz55ptVHkfxCtyJiYlllmnUqBGCg4PLfc5NmzahVq1aLx2bJEnYt2/fS5+HSA4mOVKsgIAASJIESZJgamqKJk2aYObMmcjOzq70a3/++efYtGlTucqWJzERkW64FgYpWt++fREREYH8/HycOnUKY8eORXZ2NkJCQkqUzc/Ph6mpaYVc19raukLOQ0Qvhy05UjS1Wo169erByckJI0aMwMiRIzVdZsVdjOHh4WjSpAnUajWEEHj06BHGjx8Pe3t7WFlZoWfPnjh//rzWeVesWIG6devC0tISgYGByM3N1Xr/+e7KoqIirFy5Ek2bNoVarUbDhg2xdOlSAEDjxo0BAO7u7pAkCd27d9ccFxERgZYtW8Lc3BwtWrTAunXrtK4TGxsLd3d3mJubw8PDA+fOnZP9M/rss8/QunVr1KhRA05OTpg0aRKysrJKlNu3bx+aN28Oc3Nz9OrVC8nJyVrvf/fdd+jQoQPMzc3RpEkTLF68GAUFBbLjIapITHL0SrGwsEB+fr7m9bVr17Bz507s3r1b013o5+eHe/fu4YcffsDZs2fRvn17eHt7488//wQA7Ny5E0FBQVi6dCni4+Ph4OBQIvk8b+7cuVi5ciUWLFiAK1eu4Ouvv9Y8xDg2NhYAcOTIEdy9exd79uwBAGzcuBHz58/H0qVLkZSUhGXLlmHBggWIjIwEAGRnZ6N///5wdXXF2bNnsWjRIsycOVP2z0SlUmH16tW4dOkSIiMjcezYMcyePVurTE5ODpYuXYrIyEj8/PPPyMjIwPDhwzXv//jjjxg1ahSmTp2KK1euYMOGDdi0aZMmkRPpjSBSKH9/fzFw4EDN6zNnzojatWuLt956SwghRFBQkDA1NRUpKSmaMkePHhVWVlYiNzdX61wuLi5iw4YNQgghvLy8xIQJE7Te9/T0FG3bti312hkZGUKtVouNGzeWGueNGzcEAHHu3Dmt/U5OTuLrr7/W2vfRRx8JLy8vIYQQGzZsELa2tiI7O1vzfkhISKnnepazs7P497//Xeb7O3fuFLVr19a8joiIEABETEyMZl9SUpIAIM6cOSOEEKJr165i2bJlWufZsmWLcHBw0LwGIPbu3VvmdYkqA8fkSNEOHDiAmjVroqCgAPn5+Rg4cCDWrFmjed/Z2Rl16tTRvD579iyysrJQu3ZtrfM8fvwY169fBwAkJSVhwoQJWu97eXnh+PHjpcaQlJSEvLw8eHt7lzvu1NRUJCcnIzAwEOPGjdPsLygo0Iz3JSUloW3btqhevbpWHHIdP34cy5Ytw5UrV5CRkYGCggLk5uYiOzsbNWrUAPB0pW8PDw/NMS1atECtWrWQlJSE119/HWfPnkVcXJxWy62wsBC5ubnIycnRipGoKjHJkaL16NEDISEhMDU1haOjY4mJJcVf4sWKiorg4OCAEydOlDiXrtPoLSwsZB9TVFQE4GmXpaenp9Z7JiYmAABRAatk3bp1C/369cOECRPw0UcfwdbWFqdPn0ZgYKBWty7w9BaA5xXvKyoqwuLFizFo0KASZczNzV86TiJdMcmRotWoUQNNmzYtd/n27dvj3r17qFatGho1alRqmZYtWyImJgb/+Mc/NPtiYmLKPGezZs1gYWGBo0ePYuzYsSXeNzMzA/C05VOsbt26qF+/Pn777TeMHDmy1PO2atUKW7ZswePHjzWJ9EVxlCY+Ph4FBQX49NNPoVI9HaLfuXNniXIFBQWIj4/H66+/DgC4evUqHj58iBYtWgB4+nO7evWqrJ81UVVgkiN6ho+PD7y8vPDmm29i5cqVcHV1xZ07d/DDDz/gzTffhIeHB6ZNmwZ/f394eHjgjTfewNatW3H58mU0adKk1HOam5tjzpw5mD17NszMzNClSxekpqbi8uXLCAwMhL29PSwsLBAVFYUGDRrA3Nwc1tbWWLRoEaZOnQorKyv4+voiLy8P8fHxSE9Px4wZMzBixAjMnz8fgYGB+PDDD3Hz5k188sknsj6vi4sLCgoKsGbNGgwYMAA///wz1q9fX6KcqakppkyZgtWrV8PU1BTvvfceOnXqpEl6CxcuRP/+/eHk5IShQ4dCpVLhwoULuHjxIj7++GP5/xBEFUXfg4JEleX5iSfPCwoK0posUiwjI0NMmTJFODo6ClNTU+Hk5CRGjhwpbt++rSmzdOlSYWdnJ2rWrCn8/f3F7Nmzy5x4IoQQhYWF4uOPPxbOzs7C1NRUNGzYUGuixsaNG4WTk5NQqVSiW7dumv1bt24V7dq1E2ZmZsLGxkb87W9/E3v27NG8Hx0dLdq2bSvMzMxEu3btxO7du2VPPPnss8+Eg4ODsLCwEH369BGbN28WAER6eroQ4unEE2tra7F7927RpEkTYWZmJnr27Clu3rypdd6oqCjRuXNnYWFhIaysrMTrr78uQkNDNe+DE09IDyQhKqBjn4iIyADxPjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlIsJjkiIlKs/wc3aOH0sJ8pXgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(cm))\n",
    "plt.xticks(tick_marks, ['Predicted 0', 'Predicted 1'], rotation=45)\n",
    "plt.yticks(tick_marks, ['Actual 0', 'Actual 1'])\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425909a7-6ef3-446c-b9c0-47beb1e2e2c7",
   "metadata": {},
   "source": [
    "# MultiStage Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ac649ae-e63d-4c46-b604-e480a91ae063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Base Classifiers:\n",
      "Logistic Regression: 0.79\n",
      "SVM: 0.76\n",
      "MLP: 0.75\n",
      "AdaBoost: 0.78\n",
      "Gradient Boosting: 0.78\n",
      "Random Forest: 0.78\n",
      "Accuracy of Voting Classifier: 0.805\n",
      "Accuracy of Stacking Classifier: 0.8\n",
      "Accuracy of Bagging Classifier: 0.76\n",
      "Cross-Validation Scores of Base Classifiers:\n",
      "Logistic Regression: 0.7299944618099556\n",
      "SVM: 0.7475148545521106\n",
      "MLP: 0.6962443562088744\n",
      "AdaBoost: 0.7187725868979565\n",
      "Gradient Boosting: 0.7550007978748369\n",
      "Random Forest: 0.7437507626744765\n",
      "Accuracy of Multi-Stage Ensemble: 0.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, StackingClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Suppress convergence and future warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Load the dataset\n",
    "cleaned_german_data_numeric = pd.read_excel(\"german-data-numeric.xlsx\")\n",
    "\n",
    "# Verify that 'Column25' exists in the dataset\n",
    "if 'Column25' not in cleaned_german_data_numeric.columns:\n",
    "    raise ValueError(\"The 'Column25' column is not found in the dataset.\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = cleaned_german_data_numeric.drop(columns=['Column25'])\n",
    "y = cleaned_german_data_numeric['Column25']\n",
    "\n",
    "# Polynomial features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20 ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize base classifiers\n",
    "base_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"MLP\": MLPClassifier(max_iter=200),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning with RandomizedSearchCV (reduce n_iter for faster tuning)\n",
    "param_distributions = {\n",
    "    \"Logistic Regression\": {'C': uniform(0.1, 10)},\n",
    "    \"SVM\": {'C': uniform(0.1, 10), 'kernel': ['linear', 'rbf']},\n",
    "    \"MLP\": {'hidden_layer_sizes': [(50,), (100,)], 'alpha': uniform(0.0001, 0.01)},\n",
    "    \"AdaBoost\": {'n_estimators': randint(50, 100)},\n",
    "    \"Gradient Boosting\": {'n_estimators': randint(50, 100), 'learning_rate': uniform(0.01, 0.2)},\n",
    "    \"Random Forest\": {'n_estimators': randint(50, 100), 'max_features': ['sqrt', 'log2']}\n",
    "}\n",
    "\n",
    "tuned_classifiers = {}\n",
    "for name, clf in base_classifiers.items():\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions[name], n_iter=20, cv=3, error_score=np.nan, n_jobs=-1, random_state=42)\n",
    "    random_search.fit(X_train_scaled, y_train)\n",
    "    tuned_classifiers[name] = random_search.best_estimator_\n",
    "\n",
    "# Train tuned classifiers and make predictions\n",
    "tuned_preds = {}\n",
    "for name, clf in tuned_classifiers.items():\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    tuned_preds[name] = clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate base classifiers\n",
    "tuned_accuracies = {name: accuracy_score(y_test, preds) for name, preds in tuned_preds.items()}\n",
    "print(\"Accuracy of Base Classifiers:\")\n",
    "for name, accuracy in tuned_accuracies.items():\n",
    "    print(f\"{name}: {accuracy}\")\n",
    "\n",
    "# Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(name, clf) for name, clf in tuned_classifiers.items()],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with the voting classifier\n",
    "voting_preds = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the voting classifier\n",
    "voting_accuracy = accuracy_score(y_test, voting_preds)\n",
    "print(\"Accuracy of Voting Classifier:\", voting_accuracy)\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[(name, clf) for name, clf in tuned_classifiers.items()],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "stacking_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with the stacking classifier\n",
    "stacking_preds = stacking_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the stacking classifier\n",
    "stacking_accuracy = accuracy_score(y_test, stacking_preds)\n",
    "print(\"Accuracy of Stacking Classifier:\", stacking_accuracy)\n",
    "\n",
    "# Bagging Classifier\n",
    "bagging_clf = BaggingClassifier(estimator=LogisticRegression(), n_estimators=50, random_state=42, n_jobs=-1)\n",
    "bagging_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with the bagging classifier\n",
    "bagging_preds = bagging_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the bagging classifier\n",
    "bagging_accuracy = accuracy_score(y_test, bagging_preds)\n",
    "print(\"Accuracy of Bagging Classifier:\", bagging_accuracy)\n",
    "\n",
    "# Cross-validation scores for each classifier to ensure stability (reduce cv for faster validation)\n",
    "cv_results = {name: cross_val_score(clf, X_train_scaled, y_train, cv=3).mean() for name, clf in tuned_classifiers.items()}\n",
    "print(\"Cross-Validation Scores of Base Classifiers:\")\n",
    "for name, score in cv_results.items():\n",
    "    print(f\"{name}: {score}\")\n",
    "\n",
    "# Multi-Stage Ensemble\n",
    "def bootstrap_samples(X_train_scaled, y_train, num_samples):\n",
    "    bootstrap_indices = np.random.choice(len(X_train_scaled), size=num_samples, replace=True)\n",
    "    X_bootstrap = X_train_scaled[bootstrap_indices]\n",
    "    y_bootstrap = y_train.iloc[bootstrap_indices]\n",
    "    return X_bootstrap, y_bootstrap\n",
    "\n",
    "def feature_subsample(X, num_features):\n",
    "    feature_indices = np.random.choice(X.shape[1], size=num_features, replace=False)\n",
    "    return X[:, feature_indices], feature_indices\n",
    "\n",
    "num_classifiers = 10  # Reduced for faster training\n",
    "ensemble_classifiers = []\n",
    "feature_indices_list = []\n",
    "\n",
    "for _ in range(num_classifiers):\n",
    "    X_bootstrap, y_bootstrap = bootstrap_samples(X_train_scaled, y_train, num_samples=len(X_train_scaled))\n",
    "    X_subsampled, feature_indices = feature_subsample(X_bootstrap, num_features=X_train_scaled.shape[1] // 2)\n",
    "    \n",
    "    classifiers = []\n",
    "    for name, clf in tuned_classifiers.items():\n",
    "        cloned_clf = clone(clf)\n",
    "        cloned_clf.fit(X_subsampled, y_bootstrap)\n",
    "        classifiers.append(cloned_clf)\n",
    "    \n",
    "    ensemble_classifiers.append(classifiers)\n",
    "    feature_indices_list.append(feature_indices)\n",
    "\n",
    "def multi_stage_ensemble(X_test_scaled, ensemble_classifiers, feature_indices_list):\n",
    "    preds = []\n",
    "    for classifiers, feature_indices in zip(ensemble_classifiers, feature_indices_list):\n",
    "        stage_preds = []\n",
    "        X_test_subsampled = X_test_scaled[:, feature_indices]\n",
    "        for clf in classifiers:\n",
    "            stage_preds.append(clf.predict(X_test_subsampled))\n",
    "        preds.append(np.mean(stage_preds, axis=0))\n",
    "    return np.array(preds).T\n",
    "\n",
    "ensemble_predictions = multi_stage_ensemble(X_test_scaled, ensemble_classifiers, feature_indices_list)\n",
    "final_predictions = np.round(np.mean(ensemble_predictions, axis=1)).astype(int)\n",
    "\n",
    "ensemble_accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(\"Accuracy of Multi-Stage Ensemble:\", ensemble_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7108e3d-4733-4386-803d-18e043e6dea7",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a53d5d-4411-449d-a4ca-2d20f8dd70fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.5163 - loss: 1.0203 - val_accuracy: 0.6500 - val_loss: 0.6483\n",
      "Epoch 2/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6239 - loss: 0.8493 - val_accuracy: 0.6500 - val_loss: 0.6367\n",
      "Epoch 3/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6369 - loss: 0.7849 - val_accuracy: 0.6500 - val_loss: 0.6340\n",
      "Epoch 4/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7044 - loss: 0.6900 - val_accuracy: 0.6500 - val_loss: 0.6318\n",
      "Epoch 5/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7202 - loss: 0.6733 - val_accuracy: 0.6500 - val_loss: 0.6151\n",
      "Epoch 6/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7014 - loss: 0.6508 - val_accuracy: 0.6875 - val_loss: 0.5926\n",
      "Epoch 7/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7082 - loss: 0.6512 - val_accuracy: 0.6750 - val_loss: 0.5843\n",
      "Epoch 8/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7184 - loss: 0.6133 - val_accuracy: 0.6875 - val_loss: 0.5800\n",
      "Epoch 9/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7008 - loss: 0.6152 - val_accuracy: 0.6875 - val_loss: 0.5911\n",
      "Epoch 10/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7340 - loss: 0.6141 - val_accuracy: 0.6875 - val_loss: 0.5736\n",
      "Epoch 11/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7386 - loss: 0.5642 - val_accuracy: 0.7125 - val_loss: 0.5555\n",
      "Epoch 12/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7117 - loss: 0.6256 - val_accuracy: 0.6750 - val_loss: 0.5627\n",
      "Epoch 13/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7027 - loss: 0.6137 - val_accuracy: 0.6875 - val_loss: 0.5476\n",
      "Epoch 14/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7152 - loss: 0.6064 - val_accuracy: 0.7375 - val_loss: 0.5412\n",
      "Epoch 15/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7396 - loss: 0.5542 - val_accuracy: 0.7625 - val_loss: 0.5354\n",
      "Epoch 16/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7462 - loss: 0.5819 - val_accuracy: 0.7375 - val_loss: 0.5388\n",
      "Epoch 17/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7417 - loss: 0.5625 - val_accuracy: 0.7500 - val_loss: 0.5273\n",
      "Epoch 18/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7318 - loss: 0.5451 - val_accuracy: 0.7500 - val_loss: 0.5279\n",
      "Epoch 19/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7287 - loss: 0.5673 - val_accuracy: 0.7500 - val_loss: 0.5236\n",
      "Epoch 20/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7398 - loss: 0.5395 - val_accuracy: 0.7500 - val_loss: 0.5239\n",
      "Epoch 21/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7491 - loss: 0.5225 - val_accuracy: 0.7750 - val_loss: 0.5150\n",
      "Epoch 22/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7369 - loss: 0.5540 - val_accuracy: 0.7750 - val_loss: 0.5067\n",
      "Epoch 23/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7469 - loss: 0.5408 - val_accuracy: 0.7875 - val_loss: 0.5069\n",
      "Epoch 24/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7592 - loss: 0.5291 - val_accuracy: 0.7750 - val_loss: 0.5110\n",
      "Epoch 25/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.5594 - val_accuracy: 0.7750 - val_loss: 0.5113\n",
      "Epoch 26/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7375 - loss: 0.5786 - val_accuracy: 0.7750 - val_loss: 0.5100\n",
      "Epoch 27/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7509 - loss: 0.5193 - val_accuracy: 0.8000 - val_loss: 0.5037\n",
      "Epoch 28/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7248 - loss: 0.5471 - val_accuracy: 0.7625 - val_loss: 0.5033\n",
      "Epoch 29/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7633 - loss: 0.4979 - val_accuracy: 0.7875 - val_loss: 0.4982\n",
      "Epoch 30/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7497 - loss: 0.5176 - val_accuracy: 0.7875 - val_loss: 0.5015\n",
      "Epoch 31/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.5354 - val_accuracy: 0.8000 - val_loss: 0.4954\n",
      "Epoch 32/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7809 - loss: 0.4923 - val_accuracy: 0.8000 - val_loss: 0.5024\n",
      "Epoch 33/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7764 - loss: 0.4894 - val_accuracy: 0.8000 - val_loss: 0.5117\n",
      "Epoch 34/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7437 - loss: 0.5072 - val_accuracy: 0.8000 - val_loss: 0.5058\n",
      "Epoch 35/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7674 - loss: 0.5128 - val_accuracy: 0.8125 - val_loss: 0.5047\n",
      "Epoch 36/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7450 - loss: 0.5077 - val_accuracy: 0.7875 - val_loss: 0.4987\n",
      "Epoch 37/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7721 - loss: 0.5110 - val_accuracy: 0.8000 - val_loss: 0.4922\n",
      "Epoch 38/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7566 - loss: 0.5013 - val_accuracy: 0.7625 - val_loss: 0.5027\n",
      "Epoch 39/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7652 - loss: 0.5222 - val_accuracy: 0.7750 - val_loss: 0.5025\n",
      "Epoch 40/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7215 - loss: 0.5281 - val_accuracy: 0.7625 - val_loss: 0.5095\n",
      "Epoch 41/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7957 - loss: 0.4967 - val_accuracy: 0.7875 - val_loss: 0.5066\n",
      "Epoch 42/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7754 - loss: 0.4789 - val_accuracy: 0.8125 - val_loss: 0.5063\n",
      "Epoch 43/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7717 - loss: 0.4724 - val_accuracy: 0.7750 - val_loss: 0.5064\n",
      "Epoch 44/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7737 - loss: 0.5008 - val_accuracy: 0.7875 - val_loss: 0.5036\n",
      "Epoch 45/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 0.4802 - val_accuracy: 0.7625 - val_loss: 0.5099\n",
      "Epoch 46/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.5025 - val_accuracy: 0.7750 - val_loss: 0.5109\n",
      "Epoch 47/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7582 - loss: 0.5033 - val_accuracy: 0.7875 - val_loss: 0.5114\n",
      "Epoch 48/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7784 - loss: 0.4824 - val_accuracy: 0.7750 - val_loss: 0.5156\n",
      "Epoch 49/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7666 - loss: 0.4996 - val_accuracy: 0.7750 - val_loss: 0.5160\n",
      "Epoch 50/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7624 - loss: 0.5101 - val_accuracy: 0.7750 - val_loss: 0.5087\n",
      "Epoch 51/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7542 - loss: 0.5112 - val_accuracy: 0.7750 - val_loss: 0.5080\n",
      "Epoch 52/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7554 - loss: 0.5111 - val_accuracy: 0.7750 - val_loss: 0.5159\n",
      "Epoch 53/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7583 - loss: 0.4916 - val_accuracy: 0.7750 - val_loss: 0.5124\n",
      "Epoch 54/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7723 - loss: 0.5116 - val_accuracy: 0.7750 - val_loss: 0.5099\n",
      "Epoch 55/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7678 - loss: 0.4841 - val_accuracy: 0.7750 - val_loss: 0.5074\n",
      "Epoch 56/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7417 - loss: 0.5037 - val_accuracy: 0.7875 - val_loss: 0.4985\n",
      "Epoch 57/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7966 - loss: 0.5064 - val_accuracy: 0.7875 - val_loss: 0.4841\n",
      "Epoch 58/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7886 - loss: 0.4702 - val_accuracy: 0.8000 - val_loss: 0.4867\n",
      "Epoch 59/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7936 - loss: 0.4749 - val_accuracy: 0.7875 - val_loss: 0.4947\n",
      "Epoch 60/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7885 - loss: 0.4597 - val_accuracy: 0.7875 - val_loss: 0.4950\n",
      "Epoch 61/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7710 - loss: 0.4616 - val_accuracy: 0.7875 - val_loss: 0.4968\n",
      "Epoch 62/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7553 - loss: 0.4882 - val_accuracy: 0.7875 - val_loss: 0.5040\n",
      "Epoch 63/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7486 - loss: 0.4962 - val_accuracy: 0.8000 - val_loss: 0.4835\n",
      "Epoch 64/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7742 - loss: 0.4668 - val_accuracy: 0.8000 - val_loss: 0.4884\n",
      "Epoch 65/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7400 - loss: 0.5042 - val_accuracy: 0.7750 - val_loss: 0.5002\n",
      "Epoch 66/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7817 - loss: 0.4839 - val_accuracy: 0.7750 - val_loss: 0.5202\n",
      "Epoch 67/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7719 - loss: 0.4734 - val_accuracy: 0.7875 - val_loss: 0.5061\n",
      "Epoch 68/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7554 - loss: 0.4888 - val_accuracy: 0.8000 - val_loss: 0.4958\n",
      "Epoch 69/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7918 - loss: 0.4726 - val_accuracy: 0.8000 - val_loss: 0.5061\n",
      "Epoch 70/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7490 - loss: 0.5052 - val_accuracy: 0.7750 - val_loss: 0.5186\n",
      "Epoch 71/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7943 - loss: 0.4447 - val_accuracy: 0.7750 - val_loss: 0.5195\n",
      "Epoch 72/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7821 - loss: 0.4864 - val_accuracy: 0.7625 - val_loss: 0.5158\n",
      "Epoch 73/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7469 - loss: 0.4737 - val_accuracy: 0.7750 - val_loss: 0.5191\n",
      "Epoch 74/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7654 - loss: 0.4956 - val_accuracy: 0.7750 - val_loss: 0.5139\n",
      "Epoch 75/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7527 - loss: 0.4997 - val_accuracy: 0.7875 - val_loss: 0.5077\n",
      "Epoch 76/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7600 - loss: 0.4978 - val_accuracy: 0.8000 - val_loss: 0.5012\n",
      "Epoch 77/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7858 - loss: 0.4707 - val_accuracy: 0.7750 - val_loss: 0.5162\n",
      "Epoch 78/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7917 - loss: 0.4479 - val_accuracy: 0.7750 - val_loss: 0.5106\n",
      "Epoch 79/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7798 - loss: 0.4749 - val_accuracy: 0.7875 - val_loss: 0.5222\n",
      "Epoch 80/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7650 - loss: 0.4933 - val_accuracy: 0.7750 - val_loss: 0.5094\n",
      "Epoch 81/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7691 - loss: 0.4955 - val_accuracy: 0.7750 - val_loss: 0.5143\n",
      "Epoch 82/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.4726 - val_accuracy: 0.7875 - val_loss: 0.4997\n",
      "Epoch 83/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7713 - loss: 0.4420 - val_accuracy: 0.7875 - val_loss: 0.5079\n",
      "Epoch 84/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8178 - loss: 0.4411 - val_accuracy: 0.7875 - val_loss: 0.4999\n",
      "Epoch 85/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7686 - loss: 0.4970 - val_accuracy: 0.7875 - val_loss: 0.5129\n",
      "Epoch 86/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8094 - loss: 0.4278 - val_accuracy: 0.7875 - val_loss: 0.5252\n",
      "Epoch 87/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7769 - loss: 0.4694 - val_accuracy: 0.7875 - val_loss: 0.5210\n",
      "Epoch 88/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7668 - loss: 0.4770 - val_accuracy: 0.7750 - val_loss: 0.5014\n",
      "Epoch 89/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8135 - loss: 0.4192 - val_accuracy: 0.7750 - val_loss: 0.5048\n",
      "Epoch 90/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7857 - loss: 0.4567 - val_accuracy: 0.7750 - val_loss: 0.5146\n",
      "Epoch 91/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7845 - loss: 0.4571 - val_accuracy: 0.7875 - val_loss: 0.5144\n",
      "Epoch 92/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7449 - loss: 0.5200 - val_accuracy: 0.7750 - val_loss: 0.5053\n",
      "Epoch 93/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7861 - loss: 0.4526 - val_accuracy: 0.7750 - val_loss: 0.5250\n",
      "Epoch 94/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7357 - loss: 0.5131 - val_accuracy: 0.7750 - val_loss: 0.5115\n",
      "Epoch 95/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7719 - loss: 0.4859 - val_accuracy: 0.7875 - val_loss: 0.5210\n",
      "Epoch 96/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7748 - loss: 0.4803 - val_accuracy: 0.7750 - val_loss: 0.5058\n",
      "Epoch 97/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7884 - loss: 0.4816 - val_accuracy: 0.8000 - val_loss: 0.5079\n",
      "Epoch 98/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7920 - loss: 0.4488 - val_accuracy: 0.8000 - val_loss: 0.4995\n",
      "Epoch 99/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7778 - loss: 0.4704 - val_accuracy: 0.8000 - val_loss: 0.5078\n",
      "Epoch 100/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8074 - loss: 0.4590 - val_accuracy: 0.7875 - val_loss: 0.4951\n",
      "Epoch 101/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.4526 - val_accuracy: 0.8000 - val_loss: 0.5012\n",
      "Epoch 102/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7911 - loss: 0.4462 - val_accuracy: 0.7750 - val_loss: 0.5155\n",
      "Epoch 103/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7930 - loss: 0.4745 - val_accuracy: 0.8000 - val_loss: 0.5116\n",
      "Epoch 104/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7788 - loss: 0.4580 - val_accuracy: 0.7875 - val_loss: 0.5269\n",
      "Epoch 105/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7563 - loss: 0.4949 - val_accuracy: 0.7875 - val_loss: 0.5036\n",
      "Epoch 106/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8002 - loss: 0.4431 - val_accuracy: 0.7875 - val_loss: 0.5107\n",
      "Epoch 107/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7867 - loss: 0.4582 - val_accuracy: 0.7750 - val_loss: 0.5077\n",
      "Epoch 108/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7289 - loss: 0.5132 - val_accuracy: 0.8000 - val_loss: 0.5186\n",
      "Epoch 109/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7954 - loss: 0.4497 - val_accuracy: 0.8000 - val_loss: 0.5342\n",
      "Epoch 110/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7619 - loss: 0.4718 - val_accuracy: 0.7875 - val_loss: 0.5310\n",
      "Epoch 111/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7740 - loss: 0.5014 - val_accuracy: 0.8000 - val_loss: 0.5273\n",
      "Epoch 112/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8018 - loss: 0.4213 - val_accuracy: 0.7875 - val_loss: 0.5418\n",
      "Epoch 113/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7946 - loss: 0.4148 - val_accuracy: 0.7750 - val_loss: 0.5474\n",
      "Epoch 114/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7763 - loss: 0.4575 - val_accuracy: 0.8000 - val_loss: 0.5250\n",
      "Epoch 115/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7802 - loss: 0.4459 - val_accuracy: 0.7625 - val_loss: 0.5351\n",
      "Epoch 116/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4479 - val_accuracy: 0.7625 - val_loss: 0.5280\n",
      "Epoch 117/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7711 - loss: 0.4472 - val_accuracy: 0.7750 - val_loss: 0.5327\n",
      "Epoch 118/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8096 - loss: 0.4367 - val_accuracy: 0.7750 - val_loss: 0.5394\n",
      "Epoch 119/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7801 - loss: 0.4690 - val_accuracy: 0.7625 - val_loss: 0.5315\n",
      "Epoch 120/120\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7975 - loss: 0.4344 - val_accuracy: 0.7625 - val_loss: 0.5424\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step\n",
      "Accuracy of CNN Model: 0.81\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(\"german-data-numeric.xlsx\")\n",
    "\n",
    "# Verify that 'Column25' exists in the dataset\n",
    "if 'Column25' not in data.columns:\n",
    "    raise ValueError(\"The 'Column25' column is not found in the dataset.\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Column25'])\n",
    "y = data['Column25']\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20 ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Feature selection with Relief (using mutual information as an approximation)\n",
    "def relief_feature_selection(X_train, y_train, num_features):\n",
    "    selector = SelectKBest(mutual_info_classif, k=num_features)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    return X_train_selected, selector\n",
    "\n",
    "num_features = 10  # Adjust the number of features as needed\n",
    "X_train_selected, selector = relief_feature_selection(X_train_scaled, y_train, num_features)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Reshape data for CNN\n",
    "input_shape = (X_train_selected.shape[1], 1)\n",
    "\n",
    "# One-hot encode the target variable\n",
    "y_train_encoded = to_categorical(y_train - 1)  # Assuming target labels start from 1\n",
    "y_test_encoded = to_categorical(y_test - 1)\n",
    "\n",
    "# Build and compile the CNN model\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax')  # Assuming binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_selected.reshape(-1, *input_shape), y_train_encoded, epochs=120, batch_size=16, \n",
    "                    validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_selected.reshape(-1, *input_shape))\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) + 1  # Convert to original class labels\n",
    "\n",
    "# Evaluate the performance of the CNN\n",
    "cnn_accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(\"Accuracy of CNN Model:\", cnn_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35eab44e-c39f-4f83-bf93-bc351a89f313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\psps0\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement genetic_selection (from versions: none)\n",
      "ERROR: No matching distribution found for genetic_selection\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn genetic_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cee082-14cb-4fd9-88bd-ead9c68414bd",
   "metadata": {},
   "source": [
    "# Genetic Algorithm Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5020a44-a949-479e-9856-9aa16cfd5fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                               \tstd                            \tmin                         \tmax                            \n",
      "0  \t50    \t[  0.693375  10.3        0.021311]\t[ 0.031173  6.515366  0.009813]\t[ 0.61375  1.       0.0025 ]\t[  0.74625  23.        0.03941]\n",
      "1  \t23    \t[  0.712075  12.9        0.022907]\t[ 0.025036  6.388271  0.010368]\t[ 0.6325  1.      0.0025]   \t[  0.74625   23.         0.042205]\n",
      "2  \t26    \t[  0.73205   16.04       0.025053]\t[ 0.01606   4.019751  0.00846 ]\t[ 0.685     3.        0.007289]\t[  0.7575    23.         0.042205]\n",
      "3  \t27    \t[  0.743375  15.84       0.0244  ]\t[ 0.011724  2.579612  0.007418]\t[  0.7025  12.       0.01  ]   \t[  0.76625   23.         0.037914]\n",
      "4  \t30    \t[  0.75175   15.48       0.021999]\t[ 0.010651  1.65215   0.0073  ]\t[  0.71      13.         0.006374]\t[  0.76625   20.         0.051174]\n",
      "5  \t23    \t[  0.759025  15.34       0.019693]\t[ 0.006453  1.350704  0.004242]\t[  0.7375    13.         0.011592]\t[  0.76875   18.         0.031721]\n",
      "6  \t24    \t[  0.7604    15.26       0.020094]\t[ 0.00751   1.323782  0.005926]\t[  0.73875   12.         0.011592]\t[  0.77      18.         0.038038]\n",
      "7  \t28    \t[  0.761125  15.14       0.020474]\t[ 0.007839  1.385785  0.006458]\t[  0.74125   12.         0.008292]\t[  0.77      18.         0.038038]\n",
      "8  \t32    \t[  0.7625    15.2        0.020901]\t[ 0.008074  1.311488  0.006787]\t[  0.73125   12.         0.009354]\t[  0.77      18.         0.038528]\n",
      "9  \t36    \t[  0.764825  14.96       0.019359]\t[ 0.005454  1.248359  0.00453 ]\t[  0.7425    12.         0.008292]\t[  0.77      18.         0.038038]\n",
      "10 \t29    \t[  0.759375  14.16       0.020414]\t[ 0.019609  1.433318  0.005161]\t[  0.65875   11.         0.007289]\t[  0.77      17.         0.037832]\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"deap.creator\")\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_excel(\"german-data-numeric.xlsx\")\n",
    "\n",
    "# Verify that 'Column25' exists in the dataset\n",
    "if 'Column25' not in data.columns:\n",
    "    raise ValueError(\"The 'Column25' column is not found in the dataset.\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Column25'])\n",
    "y = data['Column25']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# Set the maximum number of generations\n",
    "max_generations =10  # Reduced number of generations\n",
    "\n",
    "# Genetic Algorithm for feature selection and parameter tuning\n",
    "selection = GeneticSelectionCV(\n",
    "    estimator=ExtraTreesClassifier(n_estimators=50, random_state=42),\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    scoring=\"accuracy\",\n",
    "    max_features=X_train.shape[1],\n",
    "    n_population=50,\n",
    "    crossover_proba=0.5,\n",
    "    mutation_proba=0.1,  # Decreased mutation probability\n",
    "    n_generations=max_generations,\n",
    "    crossover_independent_proba=0.5,\n",
    "    mutation_independent_proba=0.05,\n",
    "    tournament_size=3,\n",
    "    n_gen_no_change=10,\n",
    "    caching=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the selection model\n",
    "selection.fit(X_train_std, y_train)\n",
    "\n",
    "# Transform the train and test sets using the selected features\n",
    "X_train_selected = selection.transform(X_train_std)\n",
    "X_test_selected = selection.transform(X_test_std)\n",
    "\n",
    "# Create SVM classifier\n",
    "svm = SVC(kernel='linear', C=0.1, random_state=42)\n",
    "\n",
    "# Fit the SVM classifier with the selected features\n",
    "svm.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba6e63-f430-4110-a374-de8d8f49be91",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdd3d275-0616-4a15-98b8-7a923ef9c51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1400,)\n",
      "(140, 1, 24)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"You are using a softmax over axis\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, GlobalAveragePooling1D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_excel(\"german-data-numeric.xlsx\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['Column25'])\n",
    "y = data['Column25']\n",
    "print(y.shape)\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Handle class imbalance with RandomOverSampler\n",
    "oversampler = RandomOverSampler(sampling_strategy=1.0, random_state=42)\n",
    "X, y = oversampler.fit_resample(X, y)\n",
    "print(y.shape)\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape data to fit the transformer model (batch_size, sequence_length, feature_dim)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6417d02-2d7a-49e1-8869-e7167c15d6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 - 11s - 174ms/step - accuracy: 0.6806 - loss: 1.6652 - val_accuracy: 0.2857 - val_loss: 1.9403 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.7649 - loss: 1.5199 - val_accuracy: 0.4841 - val_loss: 1.7921 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.7748 - loss: 1.4457 - val_accuracy: 0.5516 - val_loss: 1.6959 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.8046 - loss: 1.3629 - val_accuracy: 0.7262 - val_loss: 1.4644 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.8343 - loss: 1.2710 - val_accuracy: 0.7659 - val_loss: 1.3660 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.8343 - loss: 1.2179 - val_accuracy: 0.8651 - val_loss: 1.1759 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.8433 - loss: 1.1627 - val_accuracy: 0.8492 - val_loss: 1.1326 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.8472 - loss: 1.0919 - val_accuracy: 0.8532 - val_loss: 1.0845 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.8681 - loss: 1.0205 - val_accuracy: 0.9127 - val_loss: 1.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.8770 - loss: 0.9763 - val_accuracy: 0.9087 - val_loss: 0.9592 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.8800 - loss: 0.9485 - val_accuracy: 0.9286 - val_loss: 0.8804 - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.8849 - loss: 0.8988 - val_accuracy: 0.8968 - val_loss: 0.8427 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.8889 - loss: 0.8936 - val_accuracy: 0.8730 - val_loss: 0.8917 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.8869 - loss: 0.8333 - val_accuracy: 0.8929 - val_loss: 0.8413 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "63/63 - 1s - 15ms/step - accuracy: 0.9107 - loss: 0.7706 - val_accuracy: 0.9365 - val_loss: 0.7031 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9058 - loss: 0.7665 - val_accuracy: 0.9246 - val_loss: 0.6967 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.8899 - loss: 0.7696 - val_accuracy: 0.9286 - val_loss: 0.7057 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9058 - loss: 0.7148 - val_accuracy: 0.9405 - val_loss: 0.6693 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9196 - loss: 0.6780 - val_accuracy: 0.9206 - val_loss: 0.6427 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9137 - loss: 0.6712 - val_accuracy: 0.9643 - val_loss: 0.5760 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9256 - loss: 0.6276 - val_accuracy: 0.9683 - val_loss: 0.5551 - learning_rate: 5.0000e-04\n",
      "Epoch 22/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9306 - loss: 0.6111 - val_accuracy: 0.9683 - val_loss: 0.5264 - learning_rate: 5.0000e-04\n",
      "Epoch 23/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9325 - loss: 0.5841 - val_accuracy: 0.9722 - val_loss: 0.5011 - learning_rate: 5.0000e-04\n",
      "Epoch 24/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9315 - loss: 0.5639 - val_accuracy: 0.9286 - val_loss: 0.6097 - learning_rate: 5.0000e-04\n",
      "Epoch 25/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9306 - loss: 0.5607 - val_accuracy: 0.9127 - val_loss: 0.5949 - learning_rate: 5.0000e-04\n",
      "Epoch 26/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9276 - loss: 0.5682 - val_accuracy: 0.9484 - val_loss: 0.5481 - learning_rate: 5.0000e-04\n",
      "Epoch 27/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9454 - loss: 0.5370 - val_accuracy: 0.9683 - val_loss: 0.4549 - learning_rate: 5.0000e-04\n",
      "Epoch 28/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9335 - loss: 0.5330 - val_accuracy: 0.9603 - val_loss: 0.4723 - learning_rate: 5.0000e-04\n",
      "Epoch 29/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9246 - loss: 0.5535 - val_accuracy: 0.9802 - val_loss: 0.4208 - learning_rate: 5.0000e-04\n",
      "Epoch 30/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9474 - loss: 0.4819 - val_accuracy: 0.9603 - val_loss: 0.4613 - learning_rate: 5.0000e-04\n",
      "Epoch 31/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9484 - loss: 0.4815 - val_accuracy: 0.9603 - val_loss: 0.4322 - learning_rate: 5.0000e-04\n",
      "Epoch 32/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9583 - loss: 0.4578 - val_accuracy: 0.9841 - val_loss: 0.3789 - learning_rate: 5.0000e-04\n",
      "Epoch 33/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9484 - loss: 0.4432 - val_accuracy: 0.9444 - val_loss: 0.4413 - learning_rate: 5.0000e-04\n",
      "Epoch 34/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9206 - loss: 0.5101 - val_accuracy: 0.9643 - val_loss: 0.4111 - learning_rate: 5.0000e-04\n",
      "Epoch 35/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9286 - loss: 0.4953 - val_accuracy: 0.9722 - val_loss: 0.3850 - learning_rate: 5.0000e-04\n",
      "Epoch 36/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9534 - loss: 0.4304 - val_accuracy: 0.9603 - val_loss: 0.4152 - learning_rate: 5.0000e-04\n",
      "Epoch 37/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9633 - loss: 0.4150 - val_accuracy: 0.9960 - val_loss: 0.3381 - learning_rate: 5.0000e-04\n",
      "Epoch 38/200\n",
      "63/63 - 1s - 23ms/step - accuracy: 0.9405 - loss: 0.4445 - val_accuracy: 0.9762 - val_loss: 0.3838 - learning_rate: 5.0000e-04\n",
      "Epoch 39/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9435 - loss: 0.4297 - val_accuracy: 0.9881 - val_loss: 0.3428 - learning_rate: 5.0000e-04\n",
      "Epoch 40/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9583 - loss: 0.3893 - val_accuracy: 0.9881 - val_loss: 0.3126 - learning_rate: 5.0000e-04\n",
      "Epoch 41/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9732 - loss: 0.3713 - val_accuracy: 1.0000 - val_loss: 0.2943 - learning_rate: 5.0000e-04\n",
      "Epoch 42/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9663 - loss: 0.3743 - val_accuracy: 0.9921 - val_loss: 0.2929 - learning_rate: 5.0000e-04\n",
      "Epoch 43/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9643 - loss: 0.3743 - val_accuracy: 0.9722 - val_loss: 0.3347 - learning_rate: 5.0000e-04\n",
      "Epoch 44/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9464 - loss: 0.4056 - val_accuracy: 0.9881 - val_loss: 0.3010 - learning_rate: 5.0000e-04\n",
      "Epoch 45/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9732 - loss: 0.3457 - val_accuracy: 0.9762 - val_loss: 0.3205 - learning_rate: 5.0000e-04\n",
      "Epoch 46/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9673 - loss: 0.3453 - val_accuracy: 0.9286 - val_loss: 0.4842 - learning_rate: 5.0000e-04\n",
      "Epoch 47/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9444 - loss: 0.4215 - val_accuracy: 0.9563 - val_loss: 0.3505 - learning_rate: 5.0000e-04\n",
      "Epoch 48/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9583 - loss: 0.3877 - val_accuracy: 1.0000 - val_loss: 0.2778 - learning_rate: 5.0000e-04\n",
      "Epoch 49/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9732 - loss: 0.3402 - val_accuracy: 0.9881 - val_loss: 0.3125 - learning_rate: 5.0000e-04\n",
      "Epoch 50/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9583 - loss: 0.3607 - val_accuracy: 0.9921 - val_loss: 0.2805 - learning_rate: 5.0000e-04\n",
      "Epoch 51/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9762 - loss: 0.3112 - val_accuracy: 0.9960 - val_loss: 0.2691 - learning_rate: 5.0000e-04\n",
      "Epoch 52/200\n",
      "63/63 - 1s - 22ms/step - accuracy: 0.9653 - loss: 0.3425 - val_accuracy: 0.9921 - val_loss: 0.2750 - learning_rate: 5.0000e-04\n",
      "Epoch 53/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9613 - loss: 0.3454 - val_accuracy: 0.9802 - val_loss: 0.2853 - learning_rate: 5.0000e-04\n",
      "Epoch 54/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9683 - loss: 0.3187 - val_accuracy: 0.9921 - val_loss: 0.2572 - learning_rate: 5.0000e-04\n",
      "Epoch 55/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9663 - loss: 0.3217 - val_accuracy: 0.9722 - val_loss: 0.2937 - learning_rate: 5.0000e-04\n",
      "Epoch 56/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9673 - loss: 0.3291 - val_accuracy: 0.9206 - val_loss: 0.5041 - learning_rate: 5.0000e-04\n",
      "Epoch 57/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9504 - loss: 0.3499 - val_accuracy: 0.9921 - val_loss: 0.2528 - learning_rate: 5.0000e-04\n",
      "Epoch 58/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9802 - loss: 0.2914 - val_accuracy: 1.0000 - val_loss: 0.2321 - learning_rate: 5.0000e-04\n",
      "Epoch 59/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9782 - loss: 0.2917 - val_accuracy: 0.9802 - val_loss: 0.2974 - learning_rate: 5.0000e-04\n",
      "Epoch 60/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9613 - loss: 0.3357 - val_accuracy: 0.9841 - val_loss: 0.2709 - learning_rate: 5.0000e-04\n",
      "Epoch 61/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9494 - loss: 0.3480 - val_accuracy: 0.9921 - val_loss: 0.2850 - learning_rate: 5.0000e-04\n",
      "Epoch 62/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9683 - loss: 0.3261 - val_accuracy: 0.9921 - val_loss: 0.2432 - learning_rate: 5.0000e-04\n",
      "Epoch 63/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9732 - loss: 0.3013 - val_accuracy: 1.0000 - val_loss: 0.2247 - learning_rate: 5.0000e-04\n",
      "Epoch 64/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9802 - loss: 0.2755 - val_accuracy: 0.9722 - val_loss: 0.2802 - learning_rate: 5.0000e-04\n",
      "Epoch 65/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9722 - loss: 0.2835 - val_accuracy: 1.0000 - val_loss: 0.2158 - learning_rate: 5.0000e-04\n",
      "Epoch 66/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9831 - loss: 0.2525 - val_accuracy: 0.9960 - val_loss: 0.2210 - learning_rate: 5.0000e-04\n",
      "Epoch 67/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9534 - loss: 0.3329 - val_accuracy: 0.9484 - val_loss: 0.3710 - learning_rate: 5.0000e-04\n",
      "Epoch 68/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9514 - loss: 0.3550 - val_accuracy: 0.9643 - val_loss: 0.2943 - learning_rate: 5.0000e-04\n",
      "Epoch 69/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9732 - loss: 0.2881 - val_accuracy: 1.0000 - val_loss: 0.2221 - learning_rate: 5.0000e-04\n",
      "Epoch 70/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9782 - loss: 0.2697 - val_accuracy: 0.9841 - val_loss: 0.2390 - learning_rate: 5.0000e-04\n",
      "Epoch 71/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9544 - loss: 0.3433 - val_accuracy: 0.9802 - val_loss: 0.2552 - learning_rate: 5.0000e-04\n",
      "Epoch 72/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9544 - loss: 0.3242 - val_accuracy: 0.9960 - val_loss: 0.2441 - learning_rate: 5.0000e-04\n",
      "Epoch 73/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9653 - loss: 0.3117 - val_accuracy: 0.9960 - val_loss: 0.2343 - learning_rate: 5.0000e-04\n",
      "Epoch 74/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9732 - loss: 0.2791 - val_accuracy: 0.9921 - val_loss: 0.2482 - learning_rate: 5.0000e-04\n",
      "Epoch 75/200\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9851 - loss: 0.2477 - val_accuracy: 0.9881 - val_loss: 0.2583 - learning_rate: 5.0000e-04\n",
      "Epoch 76/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9851 - loss: 0.2420 - val_accuracy: 1.0000 - val_loss: 0.1972 - learning_rate: 2.5000e-04\n",
      "Epoch 77/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9921 - loss: 0.2209 - val_accuracy: 1.0000 - val_loss: 0.1944 - learning_rate: 2.5000e-04\n",
      "Epoch 78/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9921 - loss: 0.2161 - val_accuracy: 1.0000 - val_loss: 0.1988 - learning_rate: 2.5000e-04\n",
      "Epoch 79/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9931 - loss: 0.2125 - val_accuracy: 1.0000 - val_loss: 0.1858 - learning_rate: 2.5000e-04\n",
      "Epoch 80/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9891 - loss: 0.2157 - val_accuracy: 0.9841 - val_loss: 0.1968 - learning_rate: 2.5000e-04\n",
      "Epoch 81/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9861 - loss: 0.2249 - val_accuracy: 1.0000 - val_loss: 0.1824 - learning_rate: 2.5000e-04\n",
      "Epoch 82/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9921 - loss: 0.2029 - val_accuracy: 1.0000 - val_loss: 0.1788 - learning_rate: 2.5000e-04\n",
      "Epoch 83/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9851 - loss: 0.2134 - val_accuracy: 0.9762 - val_loss: 0.2202 - learning_rate: 2.5000e-04\n",
      "Epoch 84/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9851 - loss: 0.2283 - val_accuracy: 0.9921 - val_loss: 0.1914 - learning_rate: 2.5000e-04\n",
      "Epoch 85/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9940 - loss: 0.1957 - val_accuracy: 1.0000 - val_loss: 0.1725 - learning_rate: 2.5000e-04\n",
      "Epoch 86/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9891 - loss: 0.1911 - val_accuracy: 0.9921 - val_loss: 0.1828 - learning_rate: 2.5000e-04\n",
      "Epoch 87/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9960 - loss: 0.1856 - val_accuracy: 1.0000 - val_loss: 0.1671 - learning_rate: 2.5000e-04\n",
      "Epoch 88/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9990 - loss: 0.1694 - val_accuracy: 1.0000 - val_loss: 0.1624 - learning_rate: 2.5000e-04\n",
      "Epoch 89/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9980 - loss: 0.1663 - val_accuracy: 1.0000 - val_loss: 0.1584 - learning_rate: 2.5000e-04\n",
      "Epoch 90/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9911 - loss: 0.1771 - val_accuracy: 0.9960 - val_loss: 0.1643 - learning_rate: 2.5000e-04\n",
      "Epoch 91/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9940 - loss: 0.1708 - val_accuracy: 0.9960 - val_loss: 0.1693 - learning_rate: 2.5000e-04\n",
      "Epoch 92/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9821 - loss: 0.1993 - val_accuracy: 0.9921 - val_loss: 0.1803 - learning_rate: 2.5000e-04\n",
      "Epoch 93/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9712 - loss: 0.2537 - val_accuracy: 0.9762 - val_loss: 0.3198 - learning_rate: 2.5000e-04\n",
      "Epoch 94/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9792 - loss: 0.2165 - val_accuracy: 1.0000 - val_loss: 0.1773 - learning_rate: 2.5000e-04\n",
      "Epoch 95/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9911 - loss: 0.1828 - val_accuracy: 1.0000 - val_loss: 0.1636 - learning_rate: 2.5000e-04\n",
      "Epoch 96/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9871 - loss: 0.1922 - val_accuracy: 0.9841 - val_loss: 0.1992 - learning_rate: 2.5000e-04\n",
      "Epoch 97/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9861 - loss: 0.1960 - val_accuracy: 1.0000 - val_loss: 0.1561 - learning_rate: 2.5000e-04\n",
      "Epoch 98/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9831 - loss: 0.2019 - val_accuracy: 0.9802 - val_loss: 0.2110 - learning_rate: 2.5000e-04\n",
      "Epoch 99/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9881 - loss: 0.1940 - val_accuracy: 0.9960 - val_loss: 0.1622 - learning_rate: 2.5000e-04\n",
      "Epoch 100/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9911 - loss: 0.1845 - val_accuracy: 1.0000 - val_loss: 0.1572 - learning_rate: 2.5000e-04\n",
      "Epoch 101/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9970 - loss: 0.1648 - val_accuracy: 1.0000 - val_loss: 0.1568 - learning_rate: 2.5000e-04\n",
      "Epoch 102/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9931 - loss: 0.1674 - val_accuracy: 1.0000 - val_loss: 0.1531 - learning_rate: 2.5000e-04\n",
      "Epoch 103/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9940 - loss: 0.1668 - val_accuracy: 1.0000 - val_loss: 0.1482 - learning_rate: 2.5000e-04\n",
      "Epoch 104/200\n",
      "63/63 - 1s - 15ms/step - accuracy: 0.9841 - loss: 0.1951 - val_accuracy: 0.9841 - val_loss: 0.1780 - learning_rate: 2.5000e-04\n",
      "Epoch 105/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9861 - loss: 0.1860 - val_accuracy: 1.0000 - val_loss: 0.1494 - learning_rate: 2.5000e-04\n",
      "Epoch 106/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9891 - loss: 0.1720 - val_accuracy: 1.0000 - val_loss: 0.1480 - learning_rate: 2.5000e-04\n",
      "Epoch 107/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9940 - loss: 0.1613 - val_accuracy: 1.0000 - val_loss: 0.1448 - learning_rate: 2.5000e-04\n",
      "Epoch 108/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9950 - loss: 0.1596 - val_accuracy: 1.0000 - val_loss: 0.1427 - learning_rate: 2.5000e-04\n",
      "Epoch 109/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9950 - loss: 0.1564 - val_accuracy: 1.0000 - val_loss: 0.1410 - learning_rate: 2.5000e-04\n",
      "Epoch 110/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9931 - loss: 0.1573 - val_accuracy: 1.0000 - val_loss: 0.1399 - learning_rate: 2.5000e-04\n",
      "Epoch 111/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9921 - loss: 0.1663 - val_accuracy: 1.0000 - val_loss: 0.1378 - learning_rate: 2.5000e-04\n",
      "Epoch 112/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9921 - loss: 0.1550 - val_accuracy: 1.0000 - val_loss: 0.1362 - learning_rate: 2.5000e-04\n",
      "Epoch 113/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9970 - loss: 0.1481 - val_accuracy: 1.0000 - val_loss: 0.1395 - learning_rate: 2.5000e-04\n",
      "Epoch 114/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9831 - loss: 0.1896 - val_accuracy: 0.9921 - val_loss: 0.1806 - learning_rate: 2.5000e-04\n",
      "Epoch 115/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9861 - loss: 0.1732 - val_accuracy: 1.0000 - val_loss: 0.1407 - learning_rate: 2.5000e-04\n",
      "Epoch 116/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9831 - loss: 0.1798 - val_accuracy: 1.0000 - val_loss: 0.1452 - learning_rate: 2.5000e-04\n",
      "Epoch 117/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9970 - loss: 0.1575 - val_accuracy: 0.9960 - val_loss: 0.1391 - learning_rate: 2.5000e-04\n",
      "Epoch 118/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9990 - loss: 0.1393 - val_accuracy: 0.9960 - val_loss: 0.1349 - learning_rate: 2.5000e-04\n",
      "Epoch 119/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9950 - loss: 0.1444 - val_accuracy: 1.0000 - val_loss: 0.1306 - learning_rate: 2.5000e-04\n",
      "Epoch 120/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9722 - loss: 0.2083 - val_accuracy: 1.0000 - val_loss: 0.1421 - learning_rate: 2.5000e-04\n",
      "Epoch 121/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9851 - loss: 0.1730 - val_accuracy: 0.9762 - val_loss: 0.2240 - learning_rate: 2.5000e-04\n",
      "Epoch 122/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9772 - loss: 0.1794 - val_accuracy: 0.9960 - val_loss: 0.1518 - learning_rate: 2.5000e-04\n",
      "Epoch 123/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9871 - loss: 0.1667 - val_accuracy: 1.0000 - val_loss: 0.1410 - learning_rate: 2.5000e-04\n",
      "Epoch 124/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9861 - loss: 0.1771 - val_accuracy: 1.0000 - val_loss: 0.1377 - learning_rate: 2.5000e-04\n",
      "Epoch 125/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9881 - loss: 0.1694 - val_accuracy: 1.0000 - val_loss: 0.1353 - learning_rate: 2.5000e-04\n",
      "Epoch 126/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9931 - loss: 0.1538 - val_accuracy: 1.0000 - val_loss: 0.1332 - learning_rate: 2.5000e-04\n",
      "Epoch 127/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9990 - loss: 0.1467 - val_accuracy: 0.9921 - val_loss: 0.1466 - learning_rate: 2.5000e-04\n",
      "Epoch 128/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9901 - loss: 0.1600 - val_accuracy: 0.9960 - val_loss: 0.1338 - learning_rate: 2.5000e-04\n",
      "Epoch 129/200\n",
      "\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9851 - loss: 0.1883 - val_accuracy: 0.9960 - val_loss: 0.1545 - learning_rate: 2.5000e-04\n",
      "Epoch 130/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9871 - loss: 0.1763 - val_accuracy: 0.9960 - val_loss: 0.1418 - learning_rate: 1.2500e-04\n",
      "Epoch 131/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9980 - loss: 0.1450 - val_accuracy: 1.0000 - val_loss: 0.1307 - learning_rate: 1.2500e-04\n",
      "Epoch 132/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9970 - loss: 0.1376 - val_accuracy: 1.0000 - val_loss: 0.1289 - learning_rate: 1.2500e-04\n",
      "Epoch 133/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9950 - loss: 0.1373 - val_accuracy: 1.0000 - val_loss: 0.1271 - learning_rate: 1.2500e-04\n",
      "Epoch 134/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9990 - loss: 0.1331 - val_accuracy: 1.0000 - val_loss: 0.1260 - learning_rate: 1.2500e-04\n",
      "Epoch 135/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9980 - loss: 0.1353 - val_accuracy: 1.0000 - val_loss: 0.1245 - learning_rate: 1.2500e-04\n",
      "Epoch 136/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9990 - loss: 0.1312 - val_accuracy: 1.0000 - val_loss: 0.1249 - learning_rate: 1.2500e-04\n",
      "Epoch 137/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9960 - loss: 0.1335 - val_accuracy: 1.0000 - val_loss: 0.1222 - learning_rate: 1.2500e-04\n",
      "Epoch 138/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9980 - loss: 0.1275 - val_accuracy: 1.0000 - val_loss: 0.1209 - learning_rate: 1.2500e-04\n",
      "Epoch 139/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9960 - loss: 0.1316 - val_accuracy: 1.0000 - val_loss: 0.1197 - learning_rate: 1.2500e-04\n",
      "Epoch 140/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 1.0000 - loss: 0.1209 - val_accuracy: 1.0000 - val_loss: 0.1183 - learning_rate: 1.2500e-04\n",
      "Epoch 141/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9990 - loss: 0.1229 - val_accuracy: 1.0000 - val_loss: 0.1170 - learning_rate: 1.2500e-04\n",
      "Epoch 142/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9980 - loss: 0.1222 - val_accuracy: 1.0000 - val_loss: 0.1159 - learning_rate: 1.2500e-04\n",
      "Epoch 143/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9980 - loss: 0.1208 - val_accuracy: 1.0000 - val_loss: 0.1148 - learning_rate: 1.2500e-04\n",
      "Epoch 144/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9980 - loss: 0.1219 - val_accuracy: 0.9960 - val_loss: 0.1314 - learning_rate: 1.2500e-04\n",
      "Epoch 145/200\n",
      "63/63 - 1s - 20ms/step - accuracy: 0.9980 - loss: 0.1174 - val_accuracy: 1.0000 - val_loss: 0.1128 - learning_rate: 1.2500e-04\n",
      "Epoch 146/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9980 - loss: 0.1206 - val_accuracy: 0.9960 - val_loss: 0.1253 - learning_rate: 1.2500e-04\n",
      "Epoch 147/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9901 - loss: 0.1323 - val_accuracy: 0.9921 - val_loss: 0.1298 - learning_rate: 1.2500e-04\n",
      "Epoch 148/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9950 - loss: 0.1318 - val_accuracy: 1.0000 - val_loss: 0.1113 - learning_rate: 1.2500e-04\n",
      "Epoch 149/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9931 - loss: 0.1333 - val_accuracy: 1.0000 - val_loss: 0.1113 - learning_rate: 1.2500e-04\n",
      "Epoch 150/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9990 - loss: 0.1185 - val_accuracy: 1.0000 - val_loss: 0.1106 - learning_rate: 1.2500e-04\n",
      "Epoch 151/200\n",
      "63/63 - 1s - 15ms/step - accuracy: 0.9990 - loss: 0.1134 - val_accuracy: 1.0000 - val_loss: 0.1093 - learning_rate: 1.2500e-04\n",
      "Epoch 152/200\n",
      "63/63 - 1s - 15ms/step - accuracy: 0.9990 - loss: 0.1146 - val_accuracy: 1.0000 - val_loss: 0.1081 - learning_rate: 1.2500e-04\n",
      "Epoch 153/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9990 - loss: 0.1116 - val_accuracy: 1.0000 - val_loss: 0.1071 - learning_rate: 1.2500e-04\n",
      "Epoch 154/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 1.0000 - loss: 0.1091 - val_accuracy: 1.0000 - val_loss: 0.1059 - learning_rate: 1.2500e-04\n",
      "Epoch 155/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9960 - loss: 0.1159 - val_accuracy: 1.0000 - val_loss: 0.1052 - learning_rate: 1.2500e-04\n",
      "Epoch 156/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9931 - loss: 0.1328 - val_accuracy: 1.0000 - val_loss: 0.1050 - learning_rate: 1.2500e-04\n",
      "Epoch 157/200\n",
      "63/63 - 1s - 15ms/step - accuracy: 0.9970 - loss: 0.1123 - val_accuracy: 1.0000 - val_loss: 0.1076 - learning_rate: 1.2500e-04\n",
      "Epoch 158/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9990 - loss: 0.1122 - val_accuracy: 1.0000 - val_loss: 0.1039 - learning_rate: 1.2500e-04\n",
      "Epoch 159/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9980 - loss: 0.1095 - val_accuracy: 0.9921 - val_loss: 0.1505 - learning_rate: 1.2500e-04\n",
      "Epoch 160/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9940 - loss: 0.1167 - val_accuracy: 1.0000 - val_loss: 0.1035 - learning_rate: 1.2500e-04\n",
      "Epoch 161/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9950 - loss: 0.1157 - val_accuracy: 1.0000 - val_loss: 0.1027 - learning_rate: 1.2500e-04\n",
      "Epoch 162/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9950 - loss: 0.1179 - val_accuracy: 1.0000 - val_loss: 0.1024 - learning_rate: 1.2500e-04\n",
      "Epoch 163/200\n",
      "63/63 - 1s - 15ms/step - accuracy: 0.9960 - loss: 0.1184 - val_accuracy: 1.0000 - val_loss: 0.1019 - learning_rate: 1.2500e-04\n",
      "Epoch 164/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9970 - loss: 0.1143 - val_accuracy: 1.0000 - val_loss: 0.1014 - learning_rate: 1.2500e-04\n",
      "Epoch 165/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9990 - loss: 0.1034 - val_accuracy: 1.0000 - val_loss: 0.1003 - learning_rate: 1.2500e-04\n",
      "Epoch 166/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9970 - loss: 0.1090 - val_accuracy: 1.0000 - val_loss: 0.1010 - learning_rate: 1.2500e-04\n",
      "Epoch 167/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9921 - loss: 0.1275 - val_accuracy: 1.0000 - val_loss: 0.0997 - learning_rate: 1.2500e-04\n",
      "Epoch 168/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9950 - loss: 0.1180 - val_accuracy: 1.0000 - val_loss: 0.1004 - learning_rate: 1.2500e-04\n",
      "Epoch 169/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9940 - loss: 0.1131 - val_accuracy: 1.0000 - val_loss: 0.1020 - learning_rate: 1.2500e-04\n",
      "Epoch 170/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9960 - loss: 0.1089 - val_accuracy: 1.0000 - val_loss: 0.1012 - learning_rate: 1.2500e-04\n",
      "Epoch 171/200\n",
      "63/63 - 1s - 21ms/step - accuracy: 0.9990 - loss: 0.1050 - val_accuracy: 1.0000 - val_loss: 0.0985 - learning_rate: 1.2500e-04\n",
      "Epoch 172/200\n",
      "63/63 - 3s - 40ms/step - accuracy: 0.9921 - loss: 0.1232 - val_accuracy: 1.0000 - val_loss: 0.0991 - learning_rate: 1.2500e-04\n",
      "Epoch 173/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9950 - loss: 0.1122 - val_accuracy: 1.0000 - val_loss: 0.1042 - learning_rate: 1.2500e-04\n",
      "Epoch 174/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9921 - loss: 0.1304 - val_accuracy: 1.0000 - val_loss: 0.0982 - learning_rate: 1.2500e-04\n",
      "Epoch 175/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9970 - loss: 0.1074 - val_accuracy: 1.0000 - val_loss: 0.0978 - learning_rate: 1.2500e-04\n",
      "Epoch 176/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9960 - loss: 0.1136 - val_accuracy: 1.0000 - val_loss: 0.0980 - learning_rate: 1.2500e-04\n",
      "Epoch 177/200\n",
      "63/63 - 1s - 15ms/step - accuracy: 0.9990 - loss: 0.1024 - val_accuracy: 1.0000 - val_loss: 0.0967 - learning_rate: 1.2500e-04\n",
      "Epoch 178/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9990 - loss: 0.0994 - val_accuracy: 1.0000 - val_loss: 0.0958 - learning_rate: 1.2500e-04\n",
      "Epoch 179/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9921 - loss: 0.1106 - val_accuracy: 1.0000 - val_loss: 0.0961 - learning_rate: 1.2500e-04\n",
      "Epoch 180/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9960 - loss: 0.1122 - val_accuracy: 1.0000 - val_loss: 0.0956 - learning_rate: 1.2500e-04\n",
      "Epoch 181/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9990 - loss: 0.0993 - val_accuracy: 1.0000 - val_loss: 0.0948 - learning_rate: 1.2500e-04\n",
      "Epoch 182/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9980 - loss: 0.1010 - val_accuracy: 1.0000 - val_loss: 0.0942 - learning_rate: 1.2500e-04\n",
      "Epoch 183/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9980 - loss: 0.1028 - val_accuracy: 1.0000 - val_loss: 0.0937 - learning_rate: 1.2500e-04\n",
      "Epoch 184/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 1.0000 - loss: 0.0949 - val_accuracy: 1.0000 - val_loss: 0.0927 - learning_rate: 1.2500e-04\n",
      "Epoch 185/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 1.0000 - loss: 0.0936 - val_accuracy: 1.0000 - val_loss: 0.0917 - learning_rate: 1.2500e-04\n",
      "Epoch 186/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9970 - loss: 0.0999 - val_accuracy: 1.0000 - val_loss: 0.0913 - learning_rate: 1.2500e-04\n",
      "Epoch 187/200\n",
      "63/63 - 1s - 16ms/step - accuracy: 0.9980 - loss: 0.0941 - val_accuracy: 1.0000 - val_loss: 0.0905 - learning_rate: 1.2500e-04\n",
      "Epoch 188/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9970 - loss: 0.0995 - val_accuracy: 1.0000 - val_loss: 0.0901 - learning_rate: 1.2500e-04\n",
      "Epoch 189/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9931 - loss: 0.1155 - val_accuracy: 1.0000 - val_loss: 0.0930 - learning_rate: 1.2500e-04\n",
      "Epoch 190/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9911 - loss: 0.1178 - val_accuracy: 1.0000 - val_loss: 0.0909 - learning_rate: 1.2500e-04\n",
      "Epoch 191/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9960 - loss: 0.1082 - val_accuracy: 1.0000 - val_loss: 0.0907 - learning_rate: 1.2500e-04\n",
      "Epoch 192/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9950 - loss: 0.1006 - val_accuracy: 1.0000 - val_loss: 0.0904 - learning_rate: 1.2500e-04\n",
      "Epoch 193/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9980 - loss: 0.0957 - val_accuracy: 1.0000 - val_loss: 0.0897 - learning_rate: 1.2500e-04\n",
      "Epoch 194/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9940 - loss: 0.1097 - val_accuracy: 1.0000 - val_loss: 0.0896 - learning_rate: 1.2500e-04\n",
      "Epoch 195/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9980 - loss: 0.0956 - val_accuracy: 1.0000 - val_loss: 0.0891 - learning_rate: 1.2500e-04\n",
      "Epoch 196/200\n",
      "63/63 - 1s - 17ms/step - accuracy: 0.9990 - loss: 0.0924 - val_accuracy: 1.0000 - val_loss: 0.0885 - learning_rate: 1.2500e-04\n",
      "Epoch 197/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9990 - loss: 0.0917 - val_accuracy: 1.0000 - val_loss: 0.0878 - learning_rate: 1.2500e-04\n",
      "Epoch 198/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9980 - loss: 0.0929 - val_accuracy: 1.0000 - val_loss: 0.0871 - learning_rate: 1.2500e-04\n",
      "Epoch 199/200\n",
      "63/63 - 1s - 19ms/step - accuracy: 0.9960 - loss: 0.0950 - val_accuracy: 1.0000 - val_loss: 0.0877 - learning_rate: 1.2500e-04\n",
      "Epoch 200/200\n",
      "63/63 - 1s - 18ms/step - accuracy: 0.9970 - loss: 0.0931 - val_accuracy: 0.9960 - val_loss: 0.1021 - learning_rate: 1.2500e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step\n",
      "Final Accuracy on Test Set: 0.8642857142857143\n"
     ]
    }
   ],
   "source": [
    "# Define the transformer model\n",
    "def transformer_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Transformer Block 1\n",
    "    attention_output = MultiHeadAttention(num_heads=10, key_dim=32)(inputs, inputs)  # Increase the number of heads and key dimension\n",
    "    attention_output = Dropout(0.2)(attention_output)\n",
    "    attention_output = Add()([inputs, attention_output])\n",
    "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "    \n",
    "    ffn_output = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(attention_output)  # Increase the number of units in the dense layers\n",
    "    ffn_output = BatchNormalization()(ffn_output)\n",
    "    ffn_output = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(ffn_output)\n",
    "    ffn_output = BatchNormalization()(ffn_output)\n",
    "    ffn_output = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(ffn_output)\n",
    "    ffn_output = Dense(input_shape[-1])(ffn_output)\n",
    "    ffn_output = Dropout(0.2)(ffn_output)\n",
    "    ffn_output = Add()([attention_output, ffn_output])\n",
    "    ffn_output = LayerNormalization(epsilon=1e-6)(ffn_output)\n",
    "    \n",
    "    transformer_output = GlobalAveragePooling1D()(ffn_output)\n",
    "    \n",
    "    # Additional dense layers\n",
    "    dense_output = Dense(128, activation='relu')(transformer_output)\n",
    "    dense_output = Dropout(0.5)(dense_output)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid')(dense_output)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Instantiate the model\n",
    "model = transformer_model(X_train_resampled.shape[1:])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])  # Adjust learning rate\n",
    "\n",
    "# Callbacks for learning rate reduction\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-8, verbose=2)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=200, batch_size=16, validation_split=0.2, callbacks=[reduce_lr], verbose=2)  # Increase epochs and batch size\n",
    "\n",
    "# Final evaluation on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate final accuracy\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Final Accuracy on Test Set:\", final_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f2adcac-4174-4506-ace3-65f6d99716f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8076923076923077\n",
      "Recall: 0.9\n",
      "F1-score: 0.8513513513513513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80518ff3-daa1-4217-9db5-d6e9058f4536",
   "metadata": {},
   "source": [
    "# Confusion Matrix of Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7cb6a12d-e030-486e-a41b-78b84f460627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAHFCAYAAABb+zt/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDYElEQVR4nO3de1wVdf7H8fegyE3AKyBJCop3XVHMW6XlLTNXV7uYVlpqFzWXNHWLTKwEdVszNbGshG0z61falpXpZtquaeEtDclSUbAk72KIIDC/P1zORqBx4BzPeHg9fczjwZnvzHc+w57VT5/v9ztjmKZpCgAAwEk8XB0AAABwbyQbAADAqUg2AACAU5FsAAAApyLZAAAATkWyAQAAnIpkAwAAOBXJBgAAcCqSDQAA4FQkG0AF7Nq1S/fff7/Cw8Pl7e2tmjVrqkOHDpo7d65Onjzp1Gvv2LFDPXr0UGBgoAzD0Pz58x1+DcMwFBcX5/B+f09SUpIMw5BhGNqwYUOpdtM01bRpUxmGoZ49e1boGosXL1ZSUpJd52zYsOGSMQH4fdVdHQBwtVm6dKnGjRun5s2ba8qUKWrVqpUuXLigrVu3asmSJdq8ebNWrVrltOs/8MADysnJ0YoVK1S7dm01btzY4dfYvHmzGjZs6PB+y8vf31+vvfZaqYRi48aN2r9/v/z9/Svc9+LFi1WvXj2NGjWq3Od06NBBmzdvVqtWrSp8XaAqI9kA7LB582Y98sgj6tOnj95//315eXnZ2vr06aPJkydrzZo1To3h22+/1dixY9W/f3+nXaNLly5O67s87rrrLr355pt66aWXFBAQYNv/2muvqWvXrsrOzr4icVy4cEGGYSggIMDlvxPgasYwCmCH+Ph4GYahV155pUSiUaxGjRr64x//aPtcVFSkuXPnqkWLFvLy8lJQUJDuu+8+HT58uMR5PXv2VJs2bZSSkqIbbrhBvr6+ioiI0OzZs1VUVCTpf0MMBQUFSkxMtA03SFJcXJzt518rPufgwYO2fevXr1fPnj1Vt25d+fj46Nprr9XQoUN17tw52zFlDaN8++23GjRokGrXri1vb2+1b99eycnJJY4pHm546623FBsbq9DQUAUEBKh3797au3dv+X7Jku6++25J0ltvvWXbd+bMGb333nt64IEHyjxn5syZ6ty5s+rUqaOAgAB16NBBr732mn79rsnGjRsrNTVVGzdutP3+iitDxbG/8cYbmjx5sq655hp5eXlp3759pYZRjh8/rrCwMHXr1k0XLlyw9b9nzx75+fnp3nvvLfe9AlUByQZQToWFhVq/fr06duyosLCwcp3zyCOPaNq0aerTp48++OADPfvss1qzZo26deum48ePlzg2KytLI0aM0D333KMPPvhA/fv31xNPPKF//OMfkqQBAwZo8+bNkqTbb79dmzdvtn0ur4MHD2rAgAGqUaOGXn/9da1Zs0azZ8+Wn5+f8vPzL3ne3r171a1bN6WmpmrBggVauXKlWrVqpVGjRmnu3Lmljn/yySd16NAhvfrqq3rllVf0ww8/aODAgSosLCxXnAEBAbr99tv1+uuv2/a99dZb8vDw0F133XXJe3vooYf0zjvvaOXKlRoyZIgeffRRPfvss7ZjVq1apYiICEVFRdl+f78d8nriiSeUkZGhJUuW6MMPP1RQUFCpa9WrV08rVqxQSkqKpk2bJkk6d+6c7rjjDl177bVasmRJue4TqDJMAOWSlZVlSjKHDRtWruPT0tJMSea4ceNK7P/qq69MSeaTTz5p29ejRw9TkvnVV1+VOLZVq1Zmv379SuyTZI4fP77EvhkzZphl/d952bJlpiQzPT3dNE3TfPfdd01J5s6dOy8buyRzxowZts/Dhg0zvby8zIyMjBLH9e/f3/T19TVPnz5tmqZpfv7556Yk89Zbby1x3DvvvGNKMjdv3nzZ6xbHm5KSYuvr22+/NU3TNDt16mSOGjXKNE3TbN26tdmjR49L9lNYWGheuHDBfOaZZ8y6deuaRUVFtrZLnVt8vRtvvPGSbZ9//nmJ/XPmzDElmatWrTJHjhxp+vj4mLt27brsPQJVEZUNwEk+//xzSSo1EfG6665Ty5Yt9dlnn5XYHxISouuuu67Evnbt2unQoUMOi6l9+/aqUaOGHnzwQSUnJ+vAgQPlOm/9+vXq1atXqYrOqFGjdO7cuVIVll8PJUkX70OSXffSo0cPNWnSRK+//rp2796tlJSUSw6hFMfYu3dvBQYGqlq1avL09NTTTz+tEydO6OjRo+W+7tChQ8t97JQpUzRgwADdfffdSk5O1sKFC9W2bdtynw9UFSQbQDnVq1dPvr6+Sk9PL9fxJ06ckCQ1aNCgVFtoaKitvVjdunVLHefl5aXc3NwKRFu2Jk2a6F//+peCgoI0fvx4NWnSRE2aNNGLL7542fNOnDhxyfsobv+1395L8fwWe+7FMAzdf//9+sc//qElS5aoWbNmuuGGG8o89uuvv1bfvn0lXVwttGnTJqWkpCg2Ntbu65Z1n5eLcdSoUTp//rxCQkKYqwFcAskGUE7VqlVTr169tG3btlITPMtS/A/ukSNHSrX99NNPqlevnsNi8/b2liTl5eWV2P/beSGSdMMNN+jDDz/UmTNntGXLFnXt2lUxMTFasWLFJfuvW7fuJe9DkkPv5ddGjRql48ePa8mSJbr//vsvedyKFSvk6emp1atX684771S3bt0UHR1doWuWNdH2Uo4cOaLx48erffv2OnHihB5//PEKXRNwdyQbgB2eeOIJmaapsWPHljmh8sKFC/rwww8lSTfffLMk2SZ4FktJSVFaWpp69erlsLiKV1Ts2rWrxP7iWMpSrVo1de7cWS+99JIkafv27Zc8tlevXlq/fr0tuSj297//Xb6+vk5bFnrNNddoypQpGjhwoEaOHHnJ4wzDUPXq1VWtWjXbvtzcXL3xxhuljnVUtaiwsFB33323DMPQJ598ooSEBC1cuFArV66sdN+Au+E5G4AdunbtqsTERI0bN04dO3bUI488otatW+vChQvasWOHXnnlFbVp00YDBw5U8+bN9eCDD2rhwoXy8PBQ//79dfDgQU2fPl1hYWF67LHHHBbXrbfeqjp16mj06NF65plnVL16dSUlJSkzM7PEcUuWLNH69es1YMAAXXvttTp//rxtxUfv3r0v2f+MGTO0evVq3XTTTXr66adVp04dvfnmm/roo480d+5cBQYGOuxefmv27Nm/e8yAAQM0b948DR8+XA8++KBOnDih559/vszlyW3bttWKFSv09ttvKyIiQt7e3hWaZzFjxgz9+9//1tq1axUSEqLJkydr48aNGj16tKKiohQeHm53n4C7ItkA7DR27Fhdd911euGFFzRnzhxlZWXJ09NTzZo10/DhwzVhwgTbsYmJiWrSpIlee+01vfTSSwoMDNQtt9yihISEMudoVFRAQIDWrFmjmJgY3XPPPapVq5bGjBmj/v37a8yYMbbj2rdvr7Vr12rGjBnKyspSzZo11aZNG33wwQe2OQ9lad68ub788ks9+eSTGj9+vHJzc9WyZUstW7bMridxOsvNN9+s119/XXPmzNHAgQN1zTXXaOzYsQoKCtLo0aNLHDtz5kwdOXJEY8eO1dmzZ9WoUaMSzyEpj3Xr1ikhIUHTp08vUaFKSkpSVFSU7rrrLv3nP/9RjRo1HHF7wFXPMM1fPfEGAADAwZizAQAAnIpkAwAAOBXJBgAAcCqSDQAA4FQkGwAAwKlINgAAgFPxnA0nKyoq0k8//SR/f3+7HoMMALAG0zR19uxZhYaGysPDOf+Nfv78+TKfSlwRNWrUsL3CwCpINpzsp59+KvWmTADA1SczM1MNGzZ0eL/nz5+Xj39dqeCcQ/oLCQlRenq6pRIOkg0n8/f3lyT5DPibDE8fF0cDOMd//vonV4cAOM0vZ8/qxg7NbH+fO1p+fr5UcE5erUZK1Sr51NnCfGXtSVZ+fj7JRlVSPHRiePqQbMBt1fQPcHUIgNM5fSi8ureMSiYbpmHNqZgkGwAAWIEhqbIJjUWnBpJsAABgBYbHxa2yfViQNaMCAABug8oGAABWYBgOGEax5jgKyQYAAFbAMAoAAEDFUNkAAMAKGEYBAADO5YBhFIsOWFgzKgAA4DaobAAAYAUMowAAAKdiNQoAAEDFUNkAAMAK3HgYhcoGAABWUDyMUtnNTj/++KPuuece1a1bV76+vmrfvr22bdtmazdNU3FxcQoNDZWPj4969uyp1NRUu65BsgEAgBUUVzYqu9nh1KlT6t69uzw9PfXJJ59oz549+tvf/qZatWrZjpk7d67mzZunRYsWKSUlRSEhIerTp4/Onj1b7uswjAIAQBU1Z84chYWFadmyZbZ9jRs3tv1smqbmz5+v2NhYDRkyRJKUnJys4OBgLV++XA899FC5rkNlAwAAK3DgMEp2dnaJLS8vr8xLfvDBB4qOjtYdd9yhoKAgRUVFaenSpbb29PR0ZWVlqW/fvrZ9Xl5e6tGjh7788sty3xrJBgAAVmAYDkg2Lg6jhIWFKTAw0LYlJCSUeckDBw4oMTFRkZGR+vTTT/Xwww9r4sSJ+vvf/y5JysrKkiQFBweXOC84ONjWVh4MowAA4GYyMzMVEBBg++zl5VXmcUVFRYqOjlZ8fLwkKSoqSqmpqUpMTNR9991nO874zVwQ0zRL7bscKhsAAFiBh+GYTVJAQECJ7VLJRoMGDdSqVasS+1q2bKmMjAxJUkhIiCSVqmIcPXq0VLXjsrdW7iMBAIDzuGDpa/fu3bV3794S+77//ns1atRIkhQeHq6QkBCtW7fO1p6fn6+NGzeqW7du5b4OwygAAFRRjz32mLp166b4+Hjdeeed+vrrr/XKK6/olVdekXRx+CQmJkbx8fGKjIxUZGSk4uPj5evrq+HDh5f7OiQbAABYgQueINqpUyetWrVKTzzxhJ555hmFh4dr/vz5GjFihO2YqVOnKjc3V+PGjdOpU6fUuXNnrV27Vv7+/uW+DskGAABW4KIXsd1222267bbbLt2lYSguLk5xcXEVDos5GwAAwKmobAAAYAVu/CI2kg0AAKzARcMoVwLJBgAAVuDGlQ1rpkAAAMBtUNkAAMAKGEYBAABOxTAKAABAxVDZAADAEhwwjGLRGgLJBgAAVsAwCgAAQMVQ2QAAwAoMwwGrUaxZ2SDZAADACtx46as1owIAAG6DygYAAFbgxhNESTYAALACNx5GIdkAAMAK3LiyYc0UCAAAuA0qGwAAWAHDKAAAwKkYRgEAAKgYKhsAAFiAYRgy3LSyQbIBAIAFuHOywTAKAABwKiobAABYgfHfrbJ9WBDJBgAAFsAwCgAAQAVR2QAAwALcubJBsgEAgAWQbAAAAKdy52SDORsAAMCpqGwAAGAFLH0FAADOxDAKAABABVHZAADAAi6+Yb6ylQ3HxOJoJBsAAFiAIQcMo1g022AYBQAAOBWVDQAALMCdJ4iSbAAAYAVuvPSVYRQAAOBUVDYAALACBwyjmAyjAACAS3HEnI3Kr2ZxDpINAAAswJ2TDeZsAAAAp6KyAQCAFbjxahSSDQAALIBhFAAAgAqisgEAgAW4c2WDZAMAAAtw52SDYRQAAOBUVDYAALAAd65skGwAAGAFbrz0lWEUAADgVFQ2AACwAIZRAACAU7lzssEwCgAAFlCcbFR2s0dcXFyp80NCQmztpmkqLi5OoaGh8vHxUc+ePZWammr3vZFsAABQhbVu3VpHjhyxbbt377a1zZ07V/PmzdOiRYuUkpKikJAQ9enTR2fPnrXrGgyjAABgBS5ajVK9evUS1Yxipmlq/vz5io2N1ZAhQyRJycnJCg4O1vLly/XQQw+V+xpUNgAAsABHDqNkZ2eX2PLy8i553R9++EGhoaEKDw/XsGHDdODAAUlSenq6srKy1LdvX9uxXl5e6tGjh7788ku77o1kAwAANxMWFqbAwEDblpCQUOZxnTt31t///nd9+umnWrp0qbKystStWzedOHFCWVlZkqTg4OAS5wQHB9vayuuqGEYxDEOrVq3S4MGDXR0KLGLq0PaaOrR9iX0/n85V63FvS5IWPnS97u7RtET71h+O6ZYZH12pEIFK2br7gJLe3ai0Hw7r2Mmzmv/0fbq5Wxtb+1PPv60P/rWtxDltW1yrN+dPuNKhwkEcuRolMzNTAQEBtv1eXl5lHt+/f3/bz23btlXXrl3VpEkTJScnq0uXLiX6LGaapt1xujzZyMrK0qxZs/TRRx/pxx9/VFBQkNq3b6+YmBj16tXL1eHJNE3NnDlTr7zyik6dOqXOnTvrpZdeUuvWrV0dWpWXlnlKQ+PX2j4XFhWVaP/XzsOa+PIm2+f8gsIrFhtQWbnn89U8vIEG94nWpOfeKPOY7tHN9eykO22fPT2rXanw4ASGHJBs/HfSRkBAQIlko7z8/PzUtm1b/fDDD7b/wM/KylKDBg1sxxw9erRUteP3uDTZOHjwoLp3765atWpp7ty5ateunS5cuKBPP/1U48eP13fffefK8CT9byZuUlKSmjVrpueee059+vTR3r175e/v7+rwqrSCQlNHz+Resj2/oOiy7YCV3dCphW7o1OKyx9TwrK56dfh7CI6Tl5entLQ03XDDDQoPD1dISIjWrVunqKgoSVJ+fr42btyoOXPm2NWvS+dsjBs3ToZh6Ouvv9btt9+uZs2aqXXr1po0aZK2bNlyyfOmTZumZs2aydfXVxEREZo+fbouXLhga//mm2900003yd/fXwEBAerYsaO2bt0qSTp06JAGDhyo2rVry8/PT61bt9bHH39c5nV+OxO3TZs2Sk5O1rlz57R8+XLH/jJgt4gQf3370p3aNn+olj7aQ42CapZo794yRGmJd+mrv/1JL4zppnoB3i6KFHCOrbv2q8ddMzVw9FzFzX9XJ07/4uqQUAmueM7G448/ro0bNyo9PV1fffWVbr/9dmVnZ2vkyJEyDEMxMTGKj4/XqlWr9O2332rUqFHy9fXV8OHD7bqOyyobJ0+e1Jo1azRr1iz5+fmVaq9Vq9Ylz/X391dSUpJCQ0O1e/dujR07Vv7+/po6daokacSIEYqKilJiYqKqVaumnTt3ytPTU5I0fvx45efn64svvpCfn5/27NmjmjVrlnmd35uJa8+yHzjWtn3HND7xP9qfdUb1A300efAf9HHcAF0/9X2d+iVPn31zWB98dVCZx39Ro6Ca+svtHbQqtp96xX6o/IKi378AYHHXd2quvje0U4Pg2vox66Re+vunGjPtZb298M+qUcPlI+SoCBcsfT18+LDuvvtuHT9+XPXr11eXLl20ZcsWNWrUSJI0depU5ebmaty4cbapBGvXrrW7su+yb+S+fftkmqZatLh8mbAsTz31lO3nxo0ba/LkyXr77bdtyUZGRoamTJli6zsyMtJ2fEZGhoYOHaq2bdtKkiIiIi55ncvNxD106FCZ5+Tl5ZVYYpSdnW3PraGcPvvmR9vPaZmntfWHY0p5YaiG3dhEiR/v0ftbDtravzt8WjsPnNCOBberT1RDfZSS4YKIAce6pUd728+RjUPUOrKh+o1M0Bdfp6n39W1dFxiuKitWrLhsu2EYiouLU1xcXKWu47JhFNM0JVXsOe7vvvuurr/+eoWEhKhmzZqaPn26MjL+9w/IpEmTNGbMGPXu3VuzZ8/W/v37bW0TJ07Uc889p+7du2vGjBnatWvX717Pnpm4CQkJJZYbhYWF2X1/sN+5vAKlZZ5SREjZE6J+Pp2rw8dzLtkOXO3q1w1QaFAtZfx03NWhoIJcMYxypbgs2YiMjJRhGEpLS7PrvC1btmjYsGHq37+/Vq9erR07dig2Nlb5+fm2Y+Li4pSamqoBAwZo/fr1atWqlVatWiVJGjNmjA4cOKB7771Xu3fvVnR0tBYuXFjmtYqfqPbb9cSXm4n7xBNP6MyZM7YtMzPTrvtDxdSo7qFmoYH6+VTZE0Jr1/RSaB0//XyaCaNwT6ezc5R17Izq1SGhvlqRbDhBnTp11K9fP7300kvKyckp1X769Okyz9u0aZMaNWqk2NhYRUdHKzIysswhjWbNmumxxx7T2rVrNWTIEC1btszWFhYWpocfflgrV67U5MmTtXTp0jKv9euZuMWKZ+J269atzHO8vLxsS44quvQIv2/m8Gh1axGsa+vXVIcm9bQs5ib5+3hqxb/3yc+rumYOj1Z0ZH2F1aup7i1D9ObjvXTy7Hl9nFL28BdgNedy8/Td/p/03f6fJEk/Zp3Ud/t/0pGjp3QuN0/PL12tb/Yc0o9ZJ5XyzX49OiNJtQL91Ksby/KvVobhmM2KXDqLaPHixerWrZuuu+46PfPMM2rXrp0KCgq0bt06JSYmlln1aNq0qTIyMrRixQp16tRJH330ka1qIUm5ubmaMmWKbr/9doWHh+vw4cNKSUnR0KFDJUkxMTHq37+/mjVrplOnTmn9+vVq2bJlmfH9eiZuZGSkIiMjFR8fX6GZuHCs0Lp+euXRHqrj76UT2ee1dd8x9ZvxkQ4fz5G3ZzW1vLa27ryhiQL9aujnU7n6z54sjVmwQb+cL3B16EC5pH5/WKOnvWz7/NdXVkuS/ti7o556dIj2pWfpw39t09mc86pfx1+d2jXRX58cIT9fVl3BelyabISHh2v79u2aNWuWJk+erCNHjqh+/frq2LGjEhMTyzxn0KBBeuyxxzRhwgTl5eVpwIABmj59um3ySrVq1XTixAndd999+vnnn1WvXj0NGTJEM2fOlCQVFhZq/PjxOnz4sAICAnTLLbfohRdeuGSMjpqJC8cau3DjJdvOXyjUnbPXXbIduBp0+kMT7Voz95LtS+LHXMFocCVcrExU9gmiDgrGwQyzeKYmnCI7O1uBgYHyHbxYhqePq8MBnGLHwjt//yDgKvXL2Wx1iGygM2fOOGVovPjfiYiJ76qaV+lHQdijMC9HBxbc7rRYK4oXsQEAAKfiyS8AAFiAI1/EZjUkGwAAWIAjVpNYNNdgGAUAADgXlQ0AACzAw8OQh0flShNmJc93FpINAAAsgGEUAACACqKyAQCABbAaBQAAOJU7D6OQbAAAYAHuXNlgzgYAAHAqKhsAAFiAO1c2SDYAALAAd56zwTAKAABwKiobAABYgCEHDKPImqUNkg0AACyAYRQAAIAKorIBAIAFsBoFAAA4FcMoAAAAFURlAwAAC2AYBQAAOJU7D6OQbAAAYAHuXNlgzgYAAHAqKhsAAFiBA4ZRLPoAUZINAACsgGEUAACACqKyAQCABbAaBQAAOBXDKAAAABVEZQMAAAtgGAUAADgVwygAAAAVRGUDAAALcOfKBskGAAAWwJwNAADgVO5c2WDOBgAAcCoqGwAAWADDKAAAwKkYRgEAAKggKhsAAFiAIQcMozgkEscj2QAAwAI8DEMelcw2Knu+szCMAgAAnIrKBgAAFsBqFAAA4FTuvBqFZAMAAAvwMC5ule3DipizAQAAnIrKBgAAVmA4YBjEopUNkg0AACzAnSeIMowCAACUkJAgwzAUExNj22eapuLi4hQaGiofHx/17NlTqampdvdNsgEAgAUYDvpTESkpKXrllVfUrl27Evvnzp2refPmadGiRUpJSVFISIj69Omjs2fP2tU/yQYAABZQvBqlspu9fvnlF40YMUJLly5V7dq1bftN09T8+fMVGxurIUOGqE2bNkpOTta5c+e0fPly++7N/rAAAICVZWdnl9jy8vIueez48eM1YMAA9e7du8T+9PR0ZWVlqW/fvrZ9Xl5e6tGjh7788ku74iHZAADAAoof6lXZTZLCwsIUGBho2xISEsq85ooVK7R9+/Yy27OysiRJwcHBJfYHBwfb2sqrXKtRFixYUO4OJ06caFcAAADAsatRMjMzFRAQYNvv5eVV6tjMzEz9+c9/1tq1a+Xt7X2ZPksGZZqm3Ut0y5VsvPDCC+XqzDAMkg0AAFwsICCgRLJRlm3btuno0aPq2LGjbV9hYaG++OILLVq0SHv37pV0scLRoEED2zFHjx4tVe34PeVKNtLT0+3qFAAA2OdKv2K+V69e2r17d4l9999/v1q0aKFp06YpIiJCISEhWrdunaKioiRJ+fn52rhxo+bMmWNXXBV+qFd+fr7S09PVpEkTVa/Os8EAAKiMK/1QL39/f7Vp06bEPj8/P9WtW9e2PyYmRvHx8YqMjFRkZKTi4+Pl6+ur4cOH2xWX3VnCuXPn9Oijjyo5OVmS9P333ysiIkITJ05UaGio/vKXv9jbJQAAVZ4V3/o6depU5ebmaty4cTp16pQ6d+6stWvXyt/f365+7F6N8sQTT+ibb77Rhg0bSkwo6d27t95++217uwMAABaxYcMGzZ8/3/bZMAzFxcXpyJEjOn/+vDZu3FiqGlIedlc23n//fb399tvq0qVLiQyqVatW2r9/v90BAAAA9343it3JxrFjxxQUFFRqf05OjsPLNwAAVBVXeoLolWT3MEqnTp300Ucf2T4XJxhLly5V165dHRcZAABwC3ZXNhISEnTLLbdoz549Kigo0IsvvqjU1FRt3rxZGzdudEaMAAC4PeO/W2X7sCK7KxvdunXTpk2bdO7cOTVp0kRr165VcHCwNm/eXOLBIAAAoPwc+bhyq6nQAzLatm1rW/oKAABwORVKNgoLC7Vq1SqlpaXJMAy1bNlSgwYN4uFeAABUUEVfEf/bPqzI7uzg22+/1aBBg5SVlaXmzZtLuvhgr/r16+uDDz5Q27ZtHR4kAADuzooP9XIUu+dsjBkzRq1bt9bhw4e1fft2bd++XZmZmWrXrp0efPBBZ8QIAACuYnZXNr755htt3bpVtWvXtu2rXbu2Zs2apU6dOjk0OAAAqhKLFiYqze7KRvPmzfXzzz+X2n/06FE1bdrUIUEBAFDVVPnVKNnZ2baf4+PjNXHiRMXFxalLly6SpC1btuiZZ56x+5WzAADgoio/QbRWrVolsiXTNHXnnXfa9pmmKUkaOHCgCgsLnRAmAAC4WpUr2fj888+dHQcAAFWaO69GKVey0aNHD2fHAQBAlebOjyuv8FO4zp07p4yMDOXn55fY365du0oHBQAA3EeFXjF///3365NPPimznTkbAADYj1fM/0pMTIxOnTqlLVu2yMfHR2vWrFFycrIiIyP1wQcfOCNGAADcnmE4ZrMiuysb69ev1z//+U916tRJHh4eatSokfr06aOAgAAlJCRowIABzogTAABcpeyubOTk5CgoKEiSVKdOHR07dkzSxTfBbt++3bHRAQBQRbjzQ70q9ATRvXv3SpLat2+vl19+WT/++KOWLFmiBg0aODxAAACqAoZRfiUmJkZHjhyRJM2YMUP9+vXTm2++qRo1aigpKcnR8QEAgKuc3cnGiBEjbD9HRUXp4MGD+u6773TttdeqXr16Dg0OAICqwp1Xo1T4ORvFfH191aFDB0fEAgBAleWIYRCL5hrlSzYmTZpU7g7nzZtX4WAAAKiqqvzjynfs2FGuzqx6kwAAwHV4EdsVkv7aCAUEBLg6DMApanea4OoQAKcxC/N//yAH8FAFloiW0YcVVXrOBgAAqDx3HkaxahIEAADcBJUNAAAswDAkj6q8GgUAADiXhwOSjcqe7ywMowAAAKeqULLxxhtvqHv37goNDdWhQ4ckSfPnz9c///lPhwYHAEBVwYvYfiUxMVGTJk3SrbfeqtOnT6uwsFCSVKtWLc2fP9/R8QEAUCUUD6NUdrMiu5ONhQsXaunSpYqNjVW1atVs+6Ojo7V7926HBgcAAK5+dk8QTU9PV1RUVKn9Xl5eysnJcUhQAABUNe78bhS7Kxvh4eHauXNnqf2ffPKJWrVq5YiYAACocorf+lrZzYrsrmxMmTJF48eP1/nz52Wapr7++mu99dZbSkhI0KuvvuqMGAEAcHs8rvxX7r//fhUUFGjq1Kk6d+6chg8frmuuuUYvvviihg0b5owYAQDAVaxCD/UaO3asxo4dq+PHj6uoqEhBQUGOjgsAgCrFnedsVOoJovXq1XNUHAAAVGkeqvycCw9ZM9uwO9kIDw+/7ENDDhw4UKmAAACAe7E72YiJiSnx+cKFC9qxY4fWrFmjKVOmOCouAACqFIZRfuXPf/5zmftfeuklbd26tdIBAQBQFfEitnLo37+/3nvvPUd1BwAA3ITDXjH/7rvvqk6dOo7qDgCAKsUwVOkJom4zjBIVFVVigqhpmsrKytKxY8e0ePFihwYHAEBVwZyNXxk8eHCJzx4eHqpfv7569uypFi1aOCouAADgJuxKNgoKCtS4cWP169dPISEhzooJAIAqhwmi/1W9enU98sgjysvLc1Y8AABUSYaD/liR3atROnfurB07djgjFgAAqqziykZlNyuye87GuHHjNHnyZB0+fFgdO3aUn59fifZ27do5LDgAAHD1K3ey8cADD2j+/Pm66667JEkTJ060tRmGIdM0ZRiGCgsLHR8lAABuzp3nbJQ72UhOTtbs2bOVnp7uzHgAAKiSDMO47LvHytuHFZU72TBNU5LUqFEjpwUDAADcj10TRK2aMQEAcLVzxQTRxMREtWvXTgEBAQoICFDXrl31ySef2NpN01RcXJxCQ0Pl4+Ojnj17KjU11e57s2uCaLNmzX434Th58qTdQQAAUNW54gmiDRs21OzZs9W0aVNJF6dMDBo0SDt27FDr1q01d+5czZs3T0lJSWrWrJmee+459enTR3v37pW/v3+5r2NXsjFz5kwFBgbadycAAMCSBg4cWOLzrFmzlJiYqC1btqhVq1aaP3++YmNjNWTIEEkXk5Hg4GAtX75cDz30ULmvY1eyMWzYMAUFBdlzCgAAKAcPw6j0i9iKz8/Ozi6x38vLS15eXpc9t7CwUP/3f/+nnJwcde3aVenp6crKylLfvn1L9NOjRw99+eWXdiUb5Z6zwXwNAACcx5FzNsLCwhQYGGjbEhISLnnd3bt3q2bNmvLy8tLDDz+sVatWqVWrVsrKypIkBQcHlzg+ODjY1lZedq9GAQAA1paZmamAgADb58tVNZo3b66dO3fq9OnTeu+99zRy5Eht3LjR1v7bYkPxc7XsUe5ko6ioyK6OAQCAHRwwQbT41SjFq0vKo0aNGrYJotHR0UpJSdGLL76oadOmSZKysrLUoEED2/FHjx4tVe34PXa/GwUAADiehwyHbJVlmqby8vIUHh6ukJAQrVu3ztaWn5+vjRs3qlu3bnb1afe7UQAAgOO5Yunrk08+qf79+yssLExnz57VihUrtGHDBq1Zs0aGYSgmJkbx8fGKjIxUZGSk4uPj5evrq+HDh9t1HZINAACqqJ9//ln33nuvjhw5osDAQLVr105r1qxRnz59JElTp05Vbm6uxo0bp1OnTqlz585au3atXc/YkEg2AACwBFe8iO211167bLthGIqLi1NcXFzFgxLJBgAAluDI52xYDRNEAQCAU1HZAADAAlwxQfRKIdkAAMACPOSAYRQHLH11BoZRAACAU1HZAADAAhhGAQAATuWhyg83WHW4wqpxAQAAN0FlAwAACzAMw+63qZbVhxWRbAAAYAGGVOm1JNZMNUg2AACwBJ4gCgAAUEFUNgAAsAhr1iUqj2QDAAALcOfnbDCMAgAAnIrKBgAAFsDSVwAA4FQ8QRQAAKCCqGwAAGABDKMAAACncucniDKMAgAAnIrKBgAAFsAwCgAAcCp3Xo1CsgEAgAW4c2XDqkkQAABwE1Q2AACwAHdejUKyAQCABfAiNgAAgAqisgEAgAV4yJBHJQdCKnu+s5BsAABgAQyjAAAAVBCVDQAALMD475/K9mFFJBsAAFgAwygAAAAVRGUDAAALMBywGoVhFAAAcEnuPIxCsgEAgAW4c7LBnA0AAOBUVDYAALAAlr4CAACn8jAubpXtw4oYRgEAAE5FZQMAAAtgGAUAADgVq1EAAAAqiMoGAAAWYKjywyAWLWyQbAAAYAWsRgEAAKigq6KyYRiGVq1apcGDB7s6FFhUuz8+rcwjJ0vtH337DXp+2l0uiAionAb1AxX36CD17tpa3t6e2p9xVI8++6a++S5TkjRt7K0a0reDrgmurQsXCrXzuww9t/hDbUs95OLIUVGsRnGirKwszZo1Sx999JF+/PFHBQUFqX379oqJiVGvXr1cHZ5Wrlypl19+Wdu2bdOJEye0Y8cOtW/f3tVh4TfWJ09RYaFp+5y2/yf9acIiDe4d5cKogIoJ9PfRmlcn6d/bftAdf16sY6fOKrxhPZ05m2s7Zn/GUU396//p4I/H5ePlqUfuvlkrF01Qhz/N1InTv7gwelSUO69GcWmycfDgQXXv3l21atXS3Llz1a5dO124cEGffvqpxo8fr++++86V4UmScnJy1L17d91xxx0aO3asq8PBJdSr7V/i8/zktQpvWE/dO0S6KCKg4mJG9tGPP5/ShGf+Ydv328rdu59uLfH5qfkrdd/gbmodGaovUr6/InHCsQxVfoKnRXMN187ZGDdunAzD0Ndff63bb79dzZo1U+vWrTVp0iRt2bLlkudNmzZNzZo1k6+vryIiIjR9+nRduHDB1v7NN9/opptukr+/vwICAtSxY0dt3Xrx/5iHDh3SwIEDVbt2bfn5+al169b6+OOPL3mte++9V08//bR69+7tuBuHU+VfKNA7n6RoxB+7yrBqmg9cxi03tNWOtAwtS3hA33+aoI3/mKb7Bne75PGe1atp5J+668zZc/r2+x+vYKRA+bissnHy5EmtWbNGs2bNkp+fX6n2WrVqXfJcf39/JSUlKTQ0VLt379bYsWPl7++vqVOnSpJGjBihqKgoJSYmqlq1atq5c6c8PT0lSePHj1d+fr6++OIL+fn5ac+ePapZs6bD7isvL095eXm2z9nZ2Q7rG+Xz0YZdOvNLrobf1tnVoQAV0viaenpg6A1avHy95i1bq46tG2n25NuVl1+gtz/+2nZcv+vb6NVZ98vX21NZx7P1pwmLdPJMjgsjR2V4yJBHJf8DycOitQ2XJRv79u2TaZpq0aKF3ec+9dRTtp8bN26syZMn6+2337YlGxkZGZoyZYqt78jI/5XSMzIyNHToULVt21aSFBERUZnbKCUhIUEzZ850aJ+wzz8++FK9u7ZSg/q1XB0KUCEeHoZ2pmXo2cUfSpJ2f39YLSIa6IGhN5RINv699XvdOCJBdWvV1H2Du2lZ/APqff/zOn6KORtXI4ZRnMA0L07mq0iZ+91339X111+vkJAQ1axZU9OnT1dGRoatfdKkSRozZox69+6t2bNna//+/ba2iRMn6rnnnlP37t01Y8YM7dq1q/I38ytPPPGEzpw5Y9syMzMd2j8uL+PISW34eu9lS86A1f18PFvfHcgqse/7g1lqGFK7xL5z5/OVfvi4tn57UBOfW66CwiLdO4jvPqzHZclGZGSkDMNQWlqaXedt2bJFw4YNU//+/bV69Wrt2LFDsbGxys/Ptx0TFxen1NRUDRgwQOvXr1erVq20atUqSdKYMWN04MAB3Xvvvdq9e7eio6O1cOFCh92Xl5eXAgICSmy4cpZ/uFn1a/urb/fWrg4FqLCvvjmgyEZBJfY1uTZIh7NKL+/+NcMwVMPT5YsMUVGGgzYLclmyUadOHfXr108vvfSScnJKjzGePn26zPM2bdqkRo0aKTY2VtHR0YqMjNShQ6XXlTdr1kyPPfaY1q5dqyFDhmjZsmW2trCwMD388MNauXKlJk+erKVLlzrsvuA6RUVFevPDLRo2oLOqV6/m6nCAClv81npFtw3XpFF9Fd6wnm7vF62Rf+quV//vC0mSr3cNTR83UNFtGisspLbaNW+oF2OHKzSolv752XYXR4+KMhz0xx4JCQnq1KmT/P39FRQUpMGDB2vv3r0ljjFNU3FxcQoNDZWPj4969uyp1NRUu67j0tUoixcvVmFhoa677jq99957+uGHH5SWlqYFCxaoa9euZZ7TtGlTZWRkaMWKFdq/f78WLFhgq1pIUm5uriZMmKANGzbo0KFD2rRpk1JSUtSyZUtJUkxMjD799FOlp6dr+/btWr9+va2tLCdPntTOnTu1Z88eSdLevXu1c+dOZWVlXfIcuMaGr/fqcNYp3fPHLq4OBaiUHXsydO+UpRraL1pfrojV46Nv0ZPz3tP/rbm4qq6wqEiRjYOVPGeMUt57WiteeET1atfUrQ++UGr4BbicjRs3avz48dqyZYvWrVungoIC9e3bt0QRYO7cuZo3b54WLVqklJQUhYSEqE+fPjp79my5r2OYxZMnXOTIkSOaNWuWVq9erSNHjqh+/frq2LGjHnvsMfXs2fNikL95gujUqVP1+uuvKy8vTwMGDFCXLl0UFxen06dPKz8/XyNHjtSmTZv0888/q169ehoyZIj++te/ytvbW48++qg++eQTHT58WAEBAbrlllv0wgsvqG7dumXGl5SUpPvvv7/U/hkzZiguLu537y87O1uBgYH6+cQZhlTgtmp3muDqEACnMQvzlbd7qc6ccc7f48X/Tny2M0M1/SvX/y9ns9Wr/bUVjvXYsWMKCgrSxo0bdeONN8o0TYWGhiomJkbTpk2TdHHVZXBwsObMmaOHHnqoXP26PNlwdyQbqApINuDOrlSysd5BycbN7a9VZmZmiVi9vLzk5eX1u+fv27dPkZGR2r17t9q0aaMDBw6oSZMm2r59u6Ki/vdE5kGDBqlWrVpKTk4uV1y8iA0AADcTFhamwMBA25aQkPC755imqUmTJun6669XmzZtJMk2ZSA4OLjEscHBwXZNJ2DaMgAAVuDAB22UVdn4PRMmTNCuXbv0n//8p3S3v3lMhWmadj26gmQDAAALcORbX+199MKjjz6qDz74QF988YUaNmxo2x8SEiLpYoWjQYMGtv1Hjx4tVe24HIZRAACwgOK3vlZ2s4dpmpowYYJWrlyp9evXKzw8vER7eHi4QkJCtG7dOtu+/Px8bdy4Ud26lf8BclQ2AACoosaPH6/ly5frn//8p/z9/W3zMAIDA+Xj4yPDMBQTE6P4+HhFRkYqMjJS8fHx8vX11fDhw8t9HZINAAAswBXvRklMTJQk26Mmii1btkyjRo2SdPFxE7m5uRo3bpxOnTqlzp07a+3atfL39y/3dUg2AACwAhdkG+V5+oVhGIqLiyvXs6UuhTkbAADAqahsAABgAY5cjWI1JBsAAFhARVaTlNWHFTGMAgAAnIrKBgAAFuCK1ShXCskGAABW4MbZBsMoAADAqahsAABgAaxGAQAATuXOq1FINgAAsAA3nrLBnA0AAOBcVDYAALACNy5tkGwAAGAB7jxBlGEUAADgVFQ2AACwAFajAAAAp3LjKRsMowAAAOeisgEAgBW4cWmDZAMAAAtgNQoAAEAFUdkAAMACWI0CAACcyo2nbJBsAABgCW6cbTBnAwAAOBWVDQAALMCdV6OQbAAAYAUOmCBq0VyDYRQAAOBcVDYAALAAN54fSrIBAIAluHG2wTAKAABwKiobAABYAKtRAACAU7nz48oZRgEAAE5FZQMAAAtw4/mhJBsAAFiCG2cbJBsAAFiAO08QZc4GAABwKiobAABYgCEHrEZxSCSOR7IBAIAFuPGUDYZRAACAc1HZAADAAtz5oV4kGwAAWIL7DqQwjAIAAJyKygYAABbAMAoAAHAq9x1EYRgFAAA4GZUNAAAsgGEUAADgVO78bhSSDQAArMCNJ20wZwMAADgVlQ0AACzAjQsbJBsAAFiBO08QZRgFAAA4FZUNAAAsgNUoAADAudx40gbDKAAAVFFffPGFBg4cqNDQUBmGoffff79Eu2maiouLU2hoqHx8fNSzZ0+lpqbafR2SDQAALMBw0GaPnJwc/eEPf9CiRYvKbJ87d67mzZunRYsWKSUlRSEhIerTp4/Onj1r13UYRgEAwAJcsRqlf//+6t+/f5ltpmlq/vz5io2N1ZAhQyRJycnJCg4O1vLly/XQQw+V+zpUNgAAcDPZ2dkltry8PLv7SE9PV1ZWlvr27Wvb5+XlpR49eujLL7+0qy+SDQAALMGo9J/igZSwsDAFBgbatoSEBLujycrKkiQFBweX2B8cHGxrKy+GUQAAsABHDqNkZmYqICDAtt/Ly6sSfZYMyjTNUvt+D8kGAABuJiAgoESyUREhISGSLlY4GjRoYNt/9OjRUtWO38MwCgAAKCU8PFwhISFat26dbV9+fr42btyobt262dUXlQ0AACzAFatRfvnlF+3bt8/2OT09XTt37lSdOnV07bXXKiYmRvHx8YqMjFRkZKTi4+Pl6+ur4cOH23Udkg0AACzAFY8r37p1q2666Sbb50mTJkmSRo4cqaSkJE2dOlW5ubkaN26cTp06pc6dO2vt2rXy9/e36zokGwAAVFE9e/aUaZqXbDcMQ3FxcYqLi6vUdUg2AACwAHd+xTzJBgAAFuDG72FjNQoAAHAuKhsAAFiBG5c2SDYAALAAV6xGuVIYRgEAAE5FZQMAAAtgNQoAAHAqN56yQbIBAIAluHG2wZwNAADgVFQ2AACwAHdejUKyAQCABTBBFBVW/IKbs9nZLo4EcB6zMN/VIQBOU/z9vtwLyxwh2wH/TjiiD2cg2XCys2fPSpKahoe5OBIAQGWcPXtWgYGBDu+3Ro0aCgkJUaSD/p0ICQlRjRo1HNKXoxims1O1Kq6oqEg//fST/P39ZVi1vuVGsrOzFRYWpszMTAUEBLg6HMDh+I5feaZp6uzZswoNDZWHh3PWVZw/f175+Y6pENaoUUPe3t4O6ctRqGw4mYeHhxo2bOjqMKqcgIAA/iKGW+M7fmU5o6Lxa97e3pZLEByJpa8AAMCpSDYAAIBTkWzArXh5eWnGjBny8vJydSiAU/Adx9WICaIAAMCpqGwAAACnItkAAABORbIBAACcimQDlmYYht5//31XhwE4Bd9vVBUkG3CZrKwsPfroo4qIiJCXl5fCwsI0cOBAffbZZ64OTdLFpwbGxcUpNDRUPj4+6tmzp1JTU10dFq4SVv9+r1y5Uv369VO9evVkGIZ27tzp6pDgxkg24BIHDx5Ux44dtX79es2dO1e7d+/WmjVrdNNNN2n8+PGuDk+SNHfuXM2bN0+LFi1SSkqKQkJC1KdPH9v7boBLuRq+3zk5Oerevbtmz57t6lBQFZiAC/Tv39+85pprzF9++aVU26lTp2w/SzJXrVpl+zx16lQzMjLS9PHxMcPDw82nnnrKzM/Pt7Xv3LnT7Nmzp1mzZk3T39/f7NChg5mSkmKapmkePHjQvO2228xatWqZvr6+ZqtWrcyPPvqozPiKiorMkJAQc/bs2bZ958+fNwMDA80lS5ZU8u7h7qz+/f619PR0U5K5Y8eOCt8v8Ht4NwquuJMnT2rNmjWaNWuW/Pz8SrXXqlXrkuf6+/srKSlJoaGh2r17t8aOHSt/f39NnTpVkjRixAhFRUUpMTFR1apV086dO+Xp6SlJGj9+vPLz8/XFF1/Iz89Pe/bsUc2aNcu8Tnp6urKystS3b1/bPi8vL/Xo0UNffvmlHnrooUr8BuDOrobvN3ClkWzgitu3b59M01SLFi3sPvepp56y/dy4cWNNnjxZb7/9tu0v44yMDE2ZMsXWd2RkpO34jIwMDR06VG3btpUkRUREXPI6WVlZkqTg4OAS+4ODg3Xo0CG740bVcTV8v4ErjTkbuOLM/z601jAMu8999913df311yskJEQ1a9bU9OnTlZGRYWufNGmSxowZo969e2v27Nnav3+/rW3ixIl67rnn1L17d82YMUO7du363ev9NkbTNCsUN6qOq+n7DVwpJBu44iIjI2UYhtLS0uw6b8uWLRo2bJj69++v1atXa8eOHYqNjVV+fr7tmLi4OKWmpmrAgAFav369WrVqpVWrVkmSxowZowMHDujee+/V7t27FR0drYULF5Z5rZCQEEn/q3AUO3r0aKlqB/BrV8P3G7jiXDpjBFXWLbfcYvcEuueff96MiIgocezo0aPNwMDAS15n2LBh5sCBA8ts+8tf/mK2bdu2zLbiCaJz5syx7cvLy2OCKMrF6t/vX2OCKK4EKhtwicWLF6uwsFDXXXed3nvvPf3www9KS0vTggUL1LVr1zLPadq0qTIyMrRixQrt379fCxYssP1XnSTl5uZqwoQJ2rBhgw4dOqRNmzYpJSVFLVu2lCTFxMTo008/VXp6urZv367169fb2n7LMAzFxMQoPj5eq1at0rfffqtRo0bJ19dXw4cPd/wvBG7F6t9v6eJE1p07d2rPnj2SpL1792rnzp2lqnmAQ7g620HV9dNPP5njx483GzVqZNaoUcO85pprzD/+8Y/m559/bjtGv1kaOGXKFLNu3bpmzZo1zbvuust84YUXbP/ll5eXZw4bNswMCwsza9SoYYaGhpoTJkwwc3NzTdM0zQkTJphNmjQxvby8zPr165v33nuvefz48UvGV1RUZM6YMcMMCQkxvby8zBtvvNHcvXu3M34VcENW/34vW7bMlFRqmzFjhhN+G6jqeMU8AABwKoZRAACAU5FsAAAApyLZAAAATkWyAQAAnIpkAwAAOBXJBgAAcCqSDQAA4FQkG0AVEBcXp/bt29s+jxo1SoMHD77icRw8eFCGYWjnzp2XPKZx48aaP39+uftMSkq67Gvby8swDL3//vuV7gdAaSQbgIuMGjVKhmHIMAx5enoqIiJCjz/+uHJycpx+7RdffFFJSUnlOrY8CQIAXE51VwcAVGW33HKLli1bpgsXLujf//63xowZo5ycHCUmJpY69sKFC/L09HTIdQMDAx3SDwCUB5UNwIW8vLwUEhKisLAwDR8+XCNGjLCV8ouHPl5//XVFRETIy8tLpmnqzJkzevDBBxUUFKSAgADdfPPN+uabb0r0O3v2bAUHB8vf31+jR4/W+fPnS7T/dhilqKhIc+bMUdOmTeXl5aVrr71Ws2bNkiSFh4dLkqKiomQYhnr27Gk7b9myZWrZsqW8vb3VokULLV68uMR1vv76a0VFRcnb21vR0dHasWOH3b+jefPmqW3btvLz81NYWJjGjRunX375pdRx77//vpo1ayZvb2/16dNHmZmZJdo//PBDdezYUd7e3oqIiNDMmTNVUFBgdzwA7EeyAViIj4+PLly4YPu8b98+vfPOO3rvvfdswxgDBgxQVlaWPv74Y23btk0dOnRQr169dPLkSUnSO++8oxkzZmjWrFnaunWrGjRoUCoJ+K0nnnhCc+bM0fTp07Vnzx4tX75cwcHBki4mDJL0r3/9S0eOHNHKlSslSUuXLlVsbKxmzZqltLQ0xcfHa/r06UpOTpYk5eTk6LbbblPz5s21bds2xcXF6fHHH7f7d+Lh4aEFCxbo22+/VXJystavX6+pU6eWOObcuXOaNWuWkpOTtWnTJmVnZ2vYsGG29k8//VT33HOPJk6cqD179ujll19WUlKSLaEC4GQufhEcUGWNHDnSHDRokO3zV199ZdatW9e88847TdM0zRkzZpienp7m0aNHbcd89tlnZkBAgHn+/PkSfTVp0sR8+eWXTdM0za5du5oPP/xwifbOnTubf/jDH8q8dnZ2tunl5WUuXbq0zDjT09NNSeaOHTtK7A8LCzOXL19eYt+zzz5rdu3a1TRN03z55ZfNOnXqmDk5Obb2xMTEMvv6tUaNGpkvvPDCJdvfeecds27durbPxW8v3bJli21fWlqaKcn86quvTNM0zRtuuMGMj48v0c8bb7xhNmjQwPZZv3kDKwDHYc4G4EKrV69WzZo1VVBQoAsXLmjQoEFauHChrb1Ro0aqX7++7fO2bdv0yy+/qG7duiX6yc3N1f79+yVJaWlpevjhh0u0d+3aVZ9//nmZMaSlpSkvL0+9evUqd9zHjh1TZmamRo8erbFjx9r2FxQU2OaDpKWl6Q9/+IN8fX1LxGGvzz//XPHx8dqzZ4+ys7NVUFCg8+fPKycnR35+fpKk6tWrKzo62nZOixYtVKtWLaWlpem6667Ttm3blJKSUqKSUVhYqPPnz+vcuXMlYgTgeCQbgAvddNNNSkxMlKenp0JDQ0tNAC3+x7RYUVGRGjRooA0bNpTqq6LLP318fOw+p6ioSNLFoZTOnTuXaKtWrZokyTTNCsXza4cOHdKtt96qhx9+WM8++6zq1Kmj//znPxo9enSJ4Sbp4tLV3yreV1RUpJkzZ2rIkCGljvH29q50nAAuj2QDcCE/Pz81bdq03Md36NBBWVlZql69uho3blzmMS1bttSWLVt033332fZt2bLlkn1GRkbKx8dHn332mcaMGVOqvUaNGpIuVgKKBQcH65prrtGBAwc0YsSIMvtt1aqV3njjDeXm5toSmsvFUZatW7eqoKBAf/vb3+ThcXGK2TvvvFPquIKCAm3dulXXXXedJGnv3r06ffq0WrRoIeni723v3r12/a4BOA7JBnAV6d27t7p27arBgwdrzpw5at68uX766Sd9/PHHGjx4sKKjo/XnP/9ZI0eOVHR0tK6//nq9+eabSk1NVURERJl9ent7a9q0aZo6dapq1Kih7t2769ixY0pNTdXo0aMVFBQkHx8frVmzRg0bNpS3t7cCAwMVFxeniRMnKiAgQP3791deXp62bt2qU6dOadKkSRo+fLhiY2M1evRoPfXUUzp48KCef/55u+63SZMmKigo0MKFCzVw4EBt2rRJS5YsKXWcp6enHn30US1YsECenp6aMGGCunTpYks+nn76ad12220KCwvTHXfcIQ8PD+3atUu7d+/Wc889Z///EADswmoU4CpiGIY+/vhj3XjjjXrggQfUrFkzDRs2TAcPHrStHrnrrrv09NNPa9q0aerYsaMOHTqkRx555LL9Tp8+XZMnT9bTTz+tli1b6q677tLRo0clXZwPsWDBAr388ssKDQ3VoEGDJEljxozRq6++qqSkJLVt21Y9evRQUlKSbalszZo19eGHH2rPnj2KiopSbGys5syZY9f9tm/fXvPmzdOcOXPUpk0bvfnmm0pISCh1nK+vr6ZNm6bhw4era9eu8vHx0YoVK2zt/fr10+rVq7Vu3Tp16tRJXbp00bx589SoUSO74gFQMYbpiIFVAACAS6CyAQAAnIpkAwAAOBXJBgAAcCqSDQAA4FQkGwAAwKlINgAAgFORbAAAAKci2QAAAE5FsgEAAJyKZAMAADgVyQYAAHAqkg0AAOBU/w+g22cUjbCDsQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Define class labels\n",
    "classes = ['Class 0', 'Class 1']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f17cdb8-6eb0-4fa6-8e52-70790ed514b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "AUC: 0.9142857142857144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_prob = model.predict(X_test).flatten()\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(\"AUC:\", roc_auc)\n",
    "\n",
    "# Create a DataFrame with the ROC curve data\n",
    "roc_data = pd.DataFrame({\n",
    "    'False Positive Rate': fpr,\n",
    "    'True Positive Rate': tpr,\n",
    "    'Thresholds': thresholds\n",
    "})\n",
    "\n",
    "# Save the ROC data to a CSV file\n",
    "roc_data.to_csv('roc_curve_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb157b-6f1a-44ec-adbd-554a2fbd49f3",
   "metadata": {},
   "source": [
    "# Receiver Operating Curve(ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42c24c01-77ab-41f4-affe-ba3a0428ee67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='teal', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb993881-5b51-4ea6-b011-dec0c04879be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
